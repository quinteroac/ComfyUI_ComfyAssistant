{"category": "flux", "entries": [{"source": "image-metadata", "image": "flux/flux_canny_model_example.png", "prompt": {"3": {"inputs": {"seed": 50363905047731, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "normal", "denoise": 1.0, "model": ["31", 0], "positive": ["35", 0], "negative": ["35", 1], "latent_image": ["35", 2]}, "class_type": "KSampler"}, "7": {"inputs": {"text": "", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["3", 0], "vae": ["32", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "17": {"inputs": {"image": "sd3_controlnet_example.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["9d64e7ed10ee150e1d04938e57500fd889ff0413372ee67abf27a6d197af4d48"]}, "18": {"inputs": {"low_threshold": 0.15, "high_threshold": 0.3, "image": ["17", 0]}, "class_type": "Canny"}, "19": {"inputs": {"images": ["18", 0]}, "class_type": "PreviewImage"}, "23": {"inputs": {"text": "cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a pink sweater and jeans", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "26": {"inputs": {"guidance": 30.0, "conditioning": ["23", 0]}, "class_type": "FluxGuidance"}, "31": {"inputs": {"unet_name": "flux1-canny-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "32": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "34": {"inputs": {"clip_name1": "clip_l.safetensors", "clip_name2": "t5xxl_fp16.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "35": {"inputs": {"positive": ["26", 0], "negative": ["7", 0], "vae": ["32", 0], "pixels": ["18", 0]}, "class_type": "InstructPixToPixConditioning"}}, "workflow": {"last_node_id": 35, "last_link_id": 70, "nodes": [{"id": 7, "type": "CLIPTextEncode", "pos": [307, 282], "size": [425.27801513671875, 180.6060791015625], "flags": {"collapsed": true}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 63}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [68], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 17, "type": "LoadImage", "pos": [220, 530], "size": [315, 314.0000305175781], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [49], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["sd3_controlnet_example.png", "image"]}, {"id": 19, "type": "PreviewImage", "pos": [899, 532], "size": [571.5869140625, 625.5296020507812], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 26}], "outputs": [], "properties": {"Node name for S&R": "PreviewImage"}, "widgets_values": []}, {"id": 3, "type": "KSampler", "pos": [1290, 40], "size": [315, 262], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 57}, {"name": "positive", "type": "CONDITIONING", "link": 64}, {"name": "negative", "type": "CONDITIONING", "link": 65}, {"name": "latent_image", "type": "LATENT", "link": 66}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [50363905047731, "randomize", 20, 1, "euler", "normal", 1]}, {"id": 35, "type": "InstructPixToPixConditioning", "pos": [1040, 50], "size": [235.1999969482422, 86], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 67}, {"name": "negative", "type": "CONDITIONING", "link": 68}, {"name": "vae", "type": "VAE", "link": 69}, {"name": "pixels", "type": "IMAGE", "link": 70}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [64], "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [65], "slot_index": 1}, {"name": "latent", "type": "LATENT", "links": [66], "slot_index": 2}], "properties": {"Node name for S&R": "InstructPixToPixConditioning"}, "widgets_values": []}, {"id": 8, "type": "VAEDecode", "pos": [1620, 40], "size": [210, 46], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 7}, {"name": "vae", "type": "VAE", "link": 60}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 9, "type": "SaveImage", "pos": [1850, 40], "size": [828.9535522460938, 893.8475341796875], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 32, "type": "VAELoader", "pos": [1290, 350], "size": [315, 58], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [60, 69], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 26, "type": "FluxGuidance", "pos": [700, 50], "size": [317.4000244140625, 58], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [67], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [30]}, {"id": 23, "type": "CLIPTextEncode", "pos": [260, 50], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 62}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a pink sweater and jeans"], "color": "#232", "bgcolor": "#353"}, {"id": 34, "type": "DualCLIPLoader", "pos": [-80, 110], "size": [315, 106], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [62, 63]}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "flux"]}, {"id": 31, "type": "UNETLoader", "pos": [710, -80], "size": [315, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [57], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-canny-dev.safetensors", "default"]}, {"id": 18, "type": "Canny", "pos": [560, 530], "size": [315, 82], "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 49}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [26, 70], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "Canny"}, "widgets_values": [0.15, 0.3]}], "links": [[7, 3, 0, 8, 0, "LATENT"], [9, 8, 0, 9, 0, "IMAGE"], [26, 18, 0, 19, 0, "IMAGE"], [41, 23, 0, 26, 0, "CONDITIONING"], [49, 17, 0, 18, 0, "IMAGE"], [57, 31, 0, 3, 0, "MODEL"], [60, 32, 0, 8, 1, "VAE"], [62, 34, 0, 23, 0, "CLIP"], [63, 34, 0, 7, 0, "CLIP"], [64, 35, 0, 3, 1, "CONDITIONING"], [65, 35, 1, 3, 2, "CONDITIONING"], [66, 35, 2, 3, 3, "LATENT"], [67, 26, 0, 35, 0, "CONDITIONING"], [68, 7, 0, 35, 1, "CONDITIONING"], [69, 32, 0, 35, 2, "VAE"], [70, 18, 0, 35, 3, "IMAGE"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.2100000000000009, "offset": [95.2115677027007, 125.98441549849056]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_controlnet_example.png", "prompt": {"3": {"inputs": {"seed": 370146334065324, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "normal", "denoise": 1.0, "model": ["20", 0], "positive": ["14", 0], "negative": ["14", 1], "latent_image": ["28", 0]}, "class_type": "KSampler"}, "7": {"inputs": {"text": "", "clip": ["20", 1]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["3", 0], "vae": ["20", 2]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "14": {"inputs": {"strength": 0.4, "start_percent": 0.0, "end_percent": 1.0, "positive": ["26", 0], "negative": ["7", 0], "control_net": ["15", 0], "vae": ["20", 2], "image": ["18", 0]}, "class_type": "ControlNetApplySD3"}, "15": {"inputs": {"control_net_name": "instantx_flux_canny.safetensors"}, "class_type": "ControlNetLoader"}, "17": {"inputs": {"image": "girl_in_field.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["daed7b7d4d3073d29811146c509cd597c87311bd0e6a61cc23795c88c8e3af98"]}, "18": {"inputs": {"low_threshold": 0.2, "high_threshold": 0.3, "image": ["17", 0]}, "class_type": "Canny"}, "19": {"inputs": {"images": ["18", 0]}, "class_type": "PreviewImage"}, "20": {"inputs": {"ckpt_name": "flux1-dev-fp8.safetensors"}, "class_type": "CheckpointLoaderSimple"}, "23": {"inputs": {"text": "anime girl smiling with long hair standing in a football arena with a single massive sword hanging from her back", "clip": ["20", 1]}, "class_type": "CLIPTextEncode"}, "26": {"inputs": {"guidance": 3.5, "conditioning": ["23", 0]}, "class_type": "FluxGuidance"}, "28": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}}, "workflow": {"last_node_id": 30, "last_link_id": 56, "nodes": [{"id": 8, "type": "VAEDecode", "pos": {"0": 1620, "1": 98, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 210, "1": 46}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 7}, {"name": "vae", "type": "VAE", "link": 29}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 9, "type": "SaveImage", "pos": {"0": 1865, "1": 99, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 828.9535522460938, "1": 893.8475341796875}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 23, "type": "CLIPTextEncode", "pos": {"0": 210, "1": 196, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 55}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["anime girl smiling with long hair standing in a football arena with a single massive sword hanging from her back"], "color": "#232", "bgcolor": "#353"}, {"id": 14, "type": "ControlNetApplySD3", "pos": {"0": 930, "1": 100, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 186}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 42}, {"name": "negative", "type": "CONDITIONING", "link": 17}, {"name": "control_net", "type": "CONTROL_NET", "link": 52}, {"name": "vae", "type": "VAE", "link": 53}, {"name": "image", "type": "IMAGE", "link": 50}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [18], "slot_index": 0, "shape": 3}, {"name": "negative", "type": "CONDITIONING", "links": [19], "slot_index": 1, "shape": 3}], "properties": {"Node name for S&R": "ControlNetApplySD3"}, "widgets_values": [0.4, 0, 1]}, {"id": 28, "type": "EmptySD3LatentImage", "pos": {"0": 930, "1": 340, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [54], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 26, "type": "FluxGuidance", "pos": {"0": 570, "1": 50, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 317.4000244140625, "1": 58}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [42], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [3.5]}, {"id": 15, "type": "ControlNetLoader", "pos": {"0": 570, "1": -60, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 58}, "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CONTROL_NET", "type": "CONTROL_NET", "links": [52], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "ControlNetLoader"}, "widgets_values": ["instantx_flux_canny.safetensors"]}, {"id": 7, "type": "CLIPTextEncode", "pos": {"0": 212, "1": 417, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 425.27801513671875, "1": 180.6060791015625}, "flags": {"collapsed": true}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 56}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [17], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 20, "type": "CheckpointLoaderSimple", "pos": {"0": -180, "1": 210, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 98}, "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [28], "slot_index": 0, "shape": 3}, {"name": "CLIP", "type": "CLIP", "links": [55, 56], "slot_index": 1, "shape": 3}, {"name": "VAE", "type": "VAE", "links": [29, 53], "slot_index": 2, "shape": 3}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["flux1-dev-fp8.safetensors"]}, {"id": 30, "type": "Note", "pos": {"0": -180, "1": 400, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 371.18792724609375, "1": 255.54762268066406}, "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [], "properties": {}, "widgets_values": ["Download the fp8 flux1-dev checkpoint here and place it under models/checkpoints. It includes the two required text encoders already so they do not need to be loaded separately. \n\nhttps://huggingface.co/Comfy-Org/flux1-dev/tree/main\n\nTips\n\n- Flux does not need a negative prompt when using cfg 1.0\n- When you make the strength of the controlnet over 0.4, the prompt has less of an effect.\n"], "color": "#432", "bgcolor": "#653"}, {"id": 18, "type": "Canny", "pos": {"0": 560, "1": 530, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 82}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 49}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [26, 50], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "Canny"}, "widgets_values": [0.2, 0.3]}, {"id": 19, "type": "PreviewImage", "pos": {"0": 900, "1": 530, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 571.5869140625, "1": 625.5296020507812}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 26}], "outputs": [], "properties": {"Node name for S&R": "PreviewImage"}}, {"id": 3, "type": "KSampler", "pos": {"0": 1280, "1": 100, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 262}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 28}, {"name": "positive", "type": "CONDITIONING", "link": 18}, {"name": "negative", "type": "CONDITIONING", "link": 19}, {"name": "latent_image", "type": "LATENT", "link": 54}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [370146334065324, "randomize", 20, 1, "euler", "normal", 1]}, {"id": 17, "type": "LoadImage", "pos": {"0": 220, "1": 530, "2": 0, "3": 0, "4": 0, "5": 0, "6": 0, "7": 0, "8": 0, "9": 0}, "size": {"0": 315, "1": 314.0000305175781}, "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [49], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["girl_in_field.png", "image"]}], "links": [[7, 3, 0, 8, 0, "LATENT"], [9, 8, 0, 9, 0, "IMAGE"], [17, 7, 0, 14, 1, "CONDITIONING"], [18, 14, 0, 3, 1, "CONDITIONING"], [19, 14, 1, 3, 2, "CONDITIONING"], [26, 18, 0, 19, 0, "IMAGE"], [28, 20, 0, 3, 0, "MODEL"], [29, 20, 2, 8, 1, "VAE"], [41, 23, 0, 26, 0, "CONDITIONING"], [42, 26, 0, 14, 0, "CONDITIONING"], [49, 17, 0, 18, 0, "IMAGE"], [50, 18, 0, 14, 4, "IMAGE"], [52, 15, 0, 14, 2, "CONTROL_NET"], [53, 20, 2, 14, 3, "VAE"], [54, 28, 0, 3, 3, "LATENT"], [55, 20, 1, 23, 0, "CLIP"], [56, 20, 1, 7, 0, "CLIP"]], "groups": [], "config": {}, "extra": {}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_depth_lora_example.png", "prompt": {"3": {"inputs": {"seed": 91050358797301, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "normal", "denoise": 1.0, "model": ["37", 0], "positive": ["35", 0], "negative": ["35", 1], "latent_image": ["35", 2]}, "class_type": "KSampler"}, "7": {"inputs": {"text": "", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["3", 0], "vae": ["32", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "17": {"inputs": {"image": "shark_depthmap.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["9baf4024f049e1d639c73606b826a24247a3eab24a61081c9ec15c3a37cbb7b6"]}, "23": {"inputs": {"text": "a photograph of a shark in the sea", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "26": {"inputs": {"guidance": 10.0, "conditioning": ["23", 0]}, "class_type": "FluxGuidance"}, "31": {"inputs": {"unet_name": "flux1-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "32": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "34": {"inputs": {"clip_name1": "clip_l.safetensors", "clip_name2": "t5xxl_fp16.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "35": {"inputs": {"positive": ["26", 0], "negative": ["7", 0], "vae": ["32", 0], "pixels": ["17", 0]}, "class_type": "InstructPixToPixConditioning"}, "37": {"inputs": {"lora_name": "flux1-depth-dev-lora.safetensors", "strength_model": 1.0, "model": ["31", 0]}, "class_type": "LoraLoaderModelOnly"}}, "workflow": {"last_node_id": 38, "last_link_id": 76, "nodes": [{"id": 8, "type": "VAEDecode", "pos": [1620, 98], "size": [210, 46], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 7}, {"name": "vae", "type": "VAE", "link": 60}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 7, "type": "CLIPTextEncode", "pos": [307, 282], "size": [425.27801513671875, 180.6060791015625], "flags": {"collapsed": true}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 63}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [68], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 34, "type": "DualCLIPLoader", "pos": [-238, 112], "size": [315, 106], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [62, 63]}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "flux"]}, {"id": 17, "type": "LoadImage", "pos": [307, 342], "size": [315, 314.0000305175781], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [71], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": null, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["shark_depthmap.png", "image"]}, {"id": 26, "type": "FluxGuidance", "pos": [621, 8], "size": [317.4000244140625, 58], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [67], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [10]}, {"id": 35, "type": "InstructPixToPixConditioning", "pos": [1018, 124], "size": [235.1999969482422, 86], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 67}, {"name": "negative", "type": "CONDITIONING", "link": 68}, {"name": "vae", "type": "VAE", "link": 69}, {"name": "pixels", "type": "IMAGE", "link": 71}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [64], "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [65], "slot_index": 1}, {"name": "latent", "type": "LATENT", "links": [73], "slot_index": 2}], "properties": {"Node name for S&R": "InstructPixToPixConditioning"}, "widgets_values": []}, {"id": 32, "type": "VAELoader", "pos": [656, 165], "size": [315, 58], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [60, 69], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 9, "type": "SaveImage", "pos": [1865, 98], "size": [722.4129638671875, 425.767578125], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 37, "type": "LoraLoaderModelOnly", "pos": [624, -172], "size": [315, 82], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 74}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [76], "slot_index": 0}], "properties": {"Node name for S&R": "LoraLoaderModelOnly"}, "widgets_values": ["flux1-depth-dev-lora.safetensors", 1]}, {"id": 23, "type": "CLIPTextEncode", "pos": [115, -17], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 62}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a photograph of a shark in the sea"], "color": "#232", "bgcolor": "#353"}, {"id": 3, "type": "KSampler", "pos": [1280, 100], "size": [315, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 76}, {"name": "positive", "type": "CONDITIONING", "link": 64}, {"name": "negative", "type": "CONDITIONING", "link": 65}, {"name": "latent_image", "type": "LATENT", "link": 73}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [91050358797301, "randomize", 20, 1, "euler", "normal", 1]}, {"id": 31, "type": "UNETLoader", "pos": [249, -171], "size": [315, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [74], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-dev.safetensors", "default"]}], "links": [[7, 3, 0, 8, 0, "LATENT"], [9, 8, 0, 9, 0, "IMAGE"], [41, 23, 0, 26, 0, "CONDITIONING"], [60, 32, 0, 8, 1, "VAE"], [62, 34, 0, 23, 0, "CLIP"], [63, 34, 0, 7, 0, "CLIP"], [64, 35, 0, 3, 1, "CONDITIONING"], [65, 35, 1, 3, 2, "CONDITIONING"], [67, 26, 0, 35, 0, "CONDITIONING"], [68, 7, 0, 35, 1, "CONDITIONING"], [69, 32, 0, 35, 2, "VAE"], [71, 17, 0, 35, 3, "IMAGE"], [73, 35, 2, 3, 3, "LATENT"], [74, 31, 0, 37, 0, "MODEL"], [76, 37, 0, 3, 0, "MODEL"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1, "offset": [248.66335817156687, 220.92852117998336]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_dev_checkpoint_example.png", "prompt": {"6": {"inputs": {"text": "cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black gold leaf pattern dress and a white apron mouth open placing a fancy black forest cake with candles on top of a dinner table of an old dark Victorian mansion lit by candlelight with a bright window to the foggy forest and very expensive stuff everywhere there are paintings on the walls", "clip": ["30", 1]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["31", 0], "vae": ["30", 2]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}, "30": {"inputs": {"ckpt_name": "flux1-dev-fp8.safetensors"}, "class_type": "CheckpointLoaderSimple"}, "31": {"inputs": {"seed": 972054013131368, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "simple", "denoise": 1.0, "model": ["30", 0], "positive": ["35", 0], "negative": ["33", 0], "latent_image": ["27", 0]}, "class_type": "KSampler"}, "33": {"inputs": {"text": "", "clip": ["30", 1]}, "class_type": "CLIPTextEncode"}, "35": {"inputs": {"guidance": 3.5, "conditioning": ["6", 0]}, "class_type": "FluxGuidance"}}, "workflow": {"last_node_id": 36, "last_link_id": 57, "nodes": [{"id": 33, "type": "CLIPTextEncode", "pos": [390, 400], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {"collapsed": true}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 54, "slot_index": 0}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [55], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [471, 455], "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [51], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "color": "#323", "bgcolor": "#535"}, {"id": 35, "type": "FluxGuidance", "pos": [576, 96], "size": {"0": 211.60000610351562, "1": 58}, "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 56}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [57], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [3.5]}, {"id": 8, "type": "VAEDecode", "pos": [1151, 195], "size": {"0": 210, "1": 46}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 52}, {"name": "vae", "type": "VAE", "link": 46}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 34, "type": "Note", "pos": [831, 501], "size": {"0": 282.8617858886719, "1": 164.08004760742188}, "flags": {}, "order": 1, "mode": 0, "properties": {"text": ""}, "widgets_values": ["Note that Flux dev and schnell do not have any negative prompt so CFG should be set to 1.0. Setting CFG to 1.0 means the negative prompt is ignored."], "color": "#432", "bgcolor": "#653"}, {"id": 30, "type": "CheckpointLoaderSimple", "pos": [48, 192], "size": {"0": 315, "1": 98}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [47], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [45, 54], "shape": 3, "slot_index": 1}, {"name": "VAE", "type": "VAE", "links": [46], "shape": 3, "slot_index": 2}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["flux1-dev-fp8.safetensors"]}, {"id": 9, "type": "SaveImage", "pos": [1375, 194], "size": {"0": 985.3012084960938, "1": 1060.3828125}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 192], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 3, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 45}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [56], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black gold leaf pattern dress and a white apron mouth open placing a fancy black forest cake with candles on top of a dinner table of an old dark Victorian mansion lit by candlelight with a bright window to the foggy forest and very expensive stuff everywhere there are paintings on the walls"], "color": "#232", "bgcolor": "#353"}, {"id": 31, "type": "KSampler", "pos": [816, 192], "size": {"0": 315, "1": 262}, "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 47}, {"name": "positive", "type": "CONDITIONING", "link": 57}, {"name": "negative", "type": "CONDITIONING", "link": 55}, {"name": "latent_image", "type": "LATENT", "link": 51}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [52], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [972054013131368, "randomize", 20, 1, "euler", "simple", 1]}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [45, 30, 1, 6, 0, "CLIP"], [46, 30, 2, 8, 1, "VAE"], [47, 30, 0, 31, 0, "MODEL"], [51, 27, 0, 31, 3, "LATENT"], [52, 31, 0, 8, 0, "LATENT"], [54, 30, 1, 33, 0, "CLIP"], [55, 33, 0, 31, 2, "CONDITIONING"], [56, 6, 0, 35, 0, "CONDITIONING"], [57, 35, 0, 31, 1, "CONDITIONING"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.1, "offset": [-26.589059860274613, -54.534600602439575]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_dev_example.png", "prompt": {"6": {"inputs": {"text": "cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black gold leaf pattern dress and a white apron mouth open holding a fancy black forest cake with candles on top in the kitchen of an old dark Victorian mansion lit by candlelight with a bright window to the foggy forest and very expensive stuff everywhere", "clip": ["11", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["13", 0], "vae": ["10", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "10": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "11": {"inputs": {"clip_name1": "t5xxl_fp16.safetensors", "clip_name2": "clip_l.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "12": {"inputs": {"unet_name": "flux1-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "13": {"inputs": {"noise": ["25", 0], "guider": ["22", 0], "sampler": ["16", 0], "sigmas": ["17", 0], "latent_image": ["27", 0]}, "class_type": "SamplerCustomAdvanced"}, "16": {"inputs": {"sampler_name": "euler"}, "class_type": "KSamplerSelect"}, "17": {"inputs": {"scheduler": "simple", "steps": 20, "denoise": 1.0, "model": ["30", 0]}, "class_type": "BasicScheduler"}, "22": {"inputs": {"model": ["30", 0], "conditioning": ["26", 0]}, "class_type": "BasicGuider"}, "25": {"inputs": {"noise_seed": 219670278747233}, "class_type": "RandomNoise"}, "26": {"inputs": {"guidance": 3.5, "conditioning": ["6", 0]}, "class_type": "FluxGuidance"}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}, "30": {"inputs": {"max_shift": 1.15, "base_shift": 0.5, "width": 1024, "height": 1024, "model": ["12", 0]}, "class_type": "ModelSamplingFlux"}}, "workflow": {"last_node_id": 37, "last_link_id": 116, "nodes": [{"id": 11, "type": "DualCLIPLoader", "pos": [48, 288], "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "CLIP", "type": "CLIP", "links": [10], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux"]}, {"id": 17, "type": "BasicScheduler", "pos": [480, 1008], "size": {"0": 315, "1": 106}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 55, "slot_index": 0}], "outputs": [{"name": "SIGMAS", "type": "SIGMAS", "links": [20], "shape": 3}], "properties": {"Node name for S&R": "BasicScheduler"}, "widgets_values": ["simple", 20, 1]}, {"id": 16, "type": "KSamplerSelect", "pos": [480, 912], "size": {"0": 315, "1": 58}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "SAMPLER", "type": "SAMPLER", "links": [19], "shape": 3}], "properties": {"Node name for S&R": "KSamplerSelect"}, "widgets_values": ["euler"]}, {"id": 26, "type": "FluxGuidance", "pos": [480, 144], "size": {"0": 317.4000244140625, "1": 58}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [42], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [3.5], "color": "#233", "bgcolor": "#355"}, {"id": 22, "type": "BasicGuider", "pos": [576, 48], "size": {"0": 222.3482666015625, "1": 46}, "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 54, "slot_index": 0}, {"name": "conditioning", "type": "CONDITIONING", "link": 42, "slot_index": 1}], "outputs": [{"name": "GUIDER", "type": "GUIDER", "links": [30], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "BasicGuider"}}, {"id": 13, "type": "SamplerCustomAdvanced", "pos": [864, 192], "size": {"0": 272.3617858886719, "1": 124.53733825683594}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "noise", "type": "NOISE", "link": 37, "slot_index": 0}, {"name": "guider", "type": "GUIDER", "link": 30, "slot_index": 1}, {"name": "sampler", "type": "SAMPLER", "link": 19, "slot_index": 2}, {"name": "sigmas", "type": "SIGMAS", "link": 20, "slot_index": 3}, {"name": "latent_image", "type": "LATENT", "link": 116, "slot_index": 4}], "outputs": [{"name": "output", "type": "LATENT", "links": [24], "shape": 3, "slot_index": 0}, {"name": "denoised_output", "type": "LATENT", "links": null, "shape": 3}], "properties": {"Node name for S&R": "SamplerCustomAdvanced"}}, {"id": 25, "type": "RandomNoise", "pos": [480, 768], "size": {"0": 315, "1": 82}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "NOISE", "type": "NOISE", "links": [37], "shape": 3}], "properties": {"Node name for S&R": "RandomNoise"}, "widgets_values": [219670278747233, "randomize"], "color": "#2a363b", "bgcolor": "#3f5159"}, {"id": 8, "type": "VAEDecode", "pos": [866, 367], "size": {"0": 210, "1": 46}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 24}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 240], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 10}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black gold leaf pattern dress and a white apron mouth open holding a fancy black forest cake with candles on top in the kitchen of an old dark Victorian mansion lit by candlelight with a bright window to the foggy forest and very expensive stuff everywhere"], "color": "#232", "bgcolor": "#353"}, {"id": 30, "type": "ModelSamplingFlux", "pos": [480, 1152], "size": {"0": 315, "1": 130}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 56, "slot_index": 0}, {"name": "width", "type": "INT", "link": 115, "widget": {"name": "width"}, "slot_index": 1}, {"name": "height", "type": "INT", "link": 114, "widget": {"name": "height"}, "slot_index": 2}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [54, 55], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "ModelSamplingFlux"}, "widgets_values": [1.15, 0.5, 1024, 1024]}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": 112, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": 113, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [116], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 34, "type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [112, 115], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 35, "type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [113, 114], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 12, "type": "UNETLoader", "pos": [48, 144], "size": {"0": 315, "1": 82}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [56], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-dev.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 9, "type": "SaveImage", "pos": [1155, 196], "size": {"0": 985.3012084960938, "1": 1060.3828125}, "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 37, "type": "Note", "pos": [480, 1344], "size": {"0": 314.99755859375, "1": 117.98363494873047}, "flags": {}, "order": 6, "mode": 0, "properties": {"text": ""}, "widgets_values": ["The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\n"], "color": "#432", "bgcolor": "#653"}, {"id": 10, "type": "VAELoader", "pos": [48, 432], "size": {"0": 311.81634521484375, "1": 60.429901123046875}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [12], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 28, "type": "Note", "pos": [48, 576], "size": {"0": 336, "1": 288}, "flags": {}, "order": 8, "mode": 0, "properties": {"text": ""}, "widgets_values": ["If you get an error in any of the nodes above make sure the files are in the correct directories.\n\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\n\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\n\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\n\nae.safetensors goes in: ComfyUI/models/vae/\n\n\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues."], "color": "#432", "bgcolor": "#653"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [10, 11, 0, 6, 0, "CLIP"], [12, 10, 0, 8, 1, "VAE"], [19, 16, 0, 13, 2, "SAMPLER"], [20, 17, 0, 13, 3, "SIGMAS"], [24, 13, 0, 8, 0, "LATENT"], [30, 22, 0, 13, 1, "GUIDER"], [37, 25, 0, 13, 0, "NOISE"], [41, 6, 0, 26, 0, "CONDITIONING"], [42, 26, 0, 22, 1, "CONDITIONING"], [54, 30, 0, 22, 0, "MODEL"], [55, 30, 0, 17, 0, "MODEL"], [56, 12, 0, 30, 0, "MODEL"], [112, 34, 0, 27, 0, "INT"], [113, 35, 0, 27, 1, "INT"], [114, 35, 0, 30, 2, "INT"], [115, 34, 0, 30, 1, "INT"], [116, 27, 0, 13, 4, "LATENT"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.1, "offset": [-0.17937541249087297, 2.2890951150661545]}, "groupNodes": {"EmptyLatentImage": {"nodes": [{"type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 0}, {"type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 1}, {"type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": null, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": null, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "index": 2}], "links": [[1, 0, 2, 0, 34, "INT"], [0, 0, 2, 1, 35, "INT"]], "external": [[0, 0, "INT"], [1, 0, "INT"], [2, 0, "LATENT"]], "config": {"0": {"output": {"0": {"name": "height"}}, "input": {"value": {"visible": true}}}, "1": {"output": {"0": {"name": "width"}}, "input": {"value": {"visible": true}}}, "2": {"input": {"width": {"visible": false}, "height": {"visible": false}}}}}}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_fill_inpaint_example.png", "prompt": {"3": {"inputs": {"seed": 656821733471329, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "normal", "denoise": 1.0, "model": ["39", 0], "positive": ["38", 0], "negative": ["38", 1], "latent_image": ["38", 2]}, "class_type": "KSampler"}, "7": {"inputs": {"text": "", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["3", 0], "vae": ["32", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "17": {"inputs": {"image": "yosemite_inpaint_example.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["1f22079c6fa64d8abe997bf4dce5f606cd8ac81f8823dff439f39aa7e18ca278"]}, "23": {"inputs": {"text": "anime girl with massive fennec ears blonde hair blue eyes wearing a pink shirt", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "26": {"inputs": {"guidance": 30.0, "conditioning": ["23", 0]}, "class_type": "FluxGuidance"}, "31": {"inputs": {"unet_name": "flux1-fill-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "32": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "34": {"inputs": {"clip_name1": "clip_l.safetensors", "clip_name2": "t5xxl_fp16.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "38": {"inputs": {"noise_mask": false, "positive": ["26", 0], "negative": ["7", 0], "vae": ["32", 0], "pixels": ["17", 0], "mask": ["17", 1]}, "class_type": "InpaintModelConditioning"}, "39": {"inputs": {"model": ["31", 0]}, "class_type": "DifferentialDiffusion"}}, "workflow": {"last_node_id": 44, "last_link_id": 100, "nodes": [{"id": 7, "type": "CLIPTextEncode", "pos": [307, 282], "size": [425.27801513671875, 180.6060791015625], "flags": {"collapsed": true}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 63}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [81], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 32, "type": "VAELoader", "pos": [1352, 422], "size": [315, 58], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [60, 82], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 26, "type": "FluxGuidance", "pos": [593, 44], "size": [317.4000244140625, 58], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [80], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [30]}, {"id": 34, "type": "DualCLIPLoader", "pos": [-237, 79], "size": [315, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [62, 63]}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "flux"]}, {"id": 39, "type": "DifferentialDiffusion", "pos": [1001, -68], "size": [277.20001220703125, 26], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 85}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [86], "slot_index": 0}], "properties": {"Node name for S&R": "DifferentialDiffusion"}, "widgets_values": []}, {"id": 8, "type": "VAEDecode", "pos": [1620, 98], "size": [210, 46], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 7}, {"name": "vae", "type": "VAE", "link": 60}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [95], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 38, "type": "InpaintModelConditioning", "pos": [952, 78], "size": [302.4000244140625, 138], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 80}, {"name": "negative", "type": "CONDITIONING", "link": 81}, {"name": "vae", "type": "VAE", "link": 82}, {"name": "pixels", "type": "IMAGE", "link": 99}, {"name": "mask", "type": "MASK", "link": 100}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [77], "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [78], "slot_index": 1}, {"name": "latent", "type": "LATENT", "links": [88], "slot_index": 2}], "properties": {"Node name for S&R": "InpaintModelConditioning"}, "widgets_values": [false]}, {"id": 9, "type": "SaveImage", "pos": [1877, 101], "size": [828.9535522460938, 893.8475341796875], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 95}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 3, "type": "KSampler", "pos": [1280, 100], "size": [315, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 86}, {"name": "positive", "type": "CONDITIONING", "link": 77}, {"name": "negative", "type": "CONDITIONING", "link": 78}, {"name": "latent_image", "type": "LATENT", "link": 88}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [656821733471329, "randomize", 20, 1, "euler", "normal", 1]}, {"id": 31, "type": "UNETLoader", "pos": [602, -120], "size": [315, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [85], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-fill-dev.safetensors", "default"]}, {"id": 17, "type": "LoadImage", "pos": [587, 312], "size": [315, 314.0000305175781], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [99], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": [100], "slot_index": 1, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["yosemite_inpaint_example.png", "image"]}, {"id": 23, "type": "CLIPTextEncode", "pos": [144, -7], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 62}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["anime girl with massive fennec ears blonde hair blue eyes wearing a pink shirt"], "color": "#232", "bgcolor": "#353"}], "links": [[7, 3, 0, 8, 0, "LATENT"], [41, 23, 0, 26, 0, "CONDITIONING"], [60, 32, 0, 8, 1, "VAE"], [62, 34, 0, 23, 0, "CLIP"], [63, 34, 0, 7, 0, "CLIP"], [77, 38, 0, 3, 1, "CONDITIONING"], [78, 38, 1, 3, 2, "CONDITIONING"], [80, 26, 0, 38, 0, "CONDITIONING"], [81, 7, 0, 38, 1, "CONDITIONING"], [82, 32, 0, 38, 2, "VAE"], [85, 31, 0, 39, 0, "MODEL"], [86, 39, 0, 3, 0, "MODEL"], [88, 38, 2, 3, 3, "LATENT"], [95, 8, 0, 9, 0, "IMAGE"], [99, 17, 0, 38, 3, "IMAGE"], [100, 17, 1, 38, 4, "MASK"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.2100000000000006, "offset": [264.68970566035966, 161.4467785071371]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_fill_outpaint_example.png", "prompt": {"3": {"inputs": {"seed": 164211176398261, "steps": 20, "cfg": 1.0, "sampler_name": "euler", "scheduler": "normal", "denoise": 1.0, "model": ["39", 0], "positive": ["38", 0], "negative": ["38", 1], "latent_image": ["38", 2]}, "class_type": "KSampler"}, "7": {"inputs": {"text": "", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["3", 0], "vae": ["32", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "17": {"inputs": {"image": "sd3_controlnet_example.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["9d64e7ed10ee150e1d04938e57500fd889ff0413372ee67abf27a6d197af4d48"]}, "23": {"inputs": {"text": "beautiful scenery", "clip": ["34", 0]}, "class_type": "CLIPTextEncode"}, "26": {"inputs": {"guidance": 30.0, "conditioning": ["23", 0]}, "class_type": "FluxGuidance"}, "31": {"inputs": {"unet_name": "flux1-fill-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "32": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "34": {"inputs": {"clip_name1": "clip_l.safetensors", "clip_name2": "t5xxl_fp16.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "38": {"inputs": {"noise_mask": false, "positive": ["26", 0], "negative": ["7", 0], "vae": ["32", 0], "pixels": ["44", 0], "mask": ["44", 1]}, "class_type": "InpaintModelConditioning"}, "39": {"inputs": {"model": ["31", 0]}, "class_type": "DifferentialDiffusion"}, "44": {"inputs": {"left": 400, "top": 0, "right": 400, "bottom": 400, "feathering": 24, "image": ["17", 0]}, "class_type": "ImagePadForOutpaint"}}, "workflow": {"last_node_id": 44, "last_link_id": 98, "nodes": [{"id": 7, "type": "CLIPTextEncode", "pos": [307, 282], "size": [425.27801513671875, 180.6060791015625], "flags": {"collapsed": true}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 63}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [81], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 32, "type": "VAELoader", "pos": [1352, 422], "size": [315, 58], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [60, 82], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 26, "type": "FluxGuidance", "pos": [593, 44], "size": [317.4000244140625, 58], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [80], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [30]}, {"id": 34, "type": "DualCLIPLoader", "pos": [-237, 79], "size": [315, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [62, 63]}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "flux"]}, {"id": 39, "type": "DifferentialDiffusion", "pos": [1001, -68], "size": [277.20001220703125, 26], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 85}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [86], "slot_index": 0}], "properties": {"Node name for S&R": "DifferentialDiffusion"}, "widgets_values": []}, {"id": 8, "type": "VAEDecode", "pos": [1620, 98], "size": [210, 46], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 7}, {"name": "vae", "type": "VAE", "link": 60}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [95], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 38, "type": "InpaintModelConditioning", "pos": [952, 78], "size": [302.4000244140625, 138], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 80}, {"name": "negative", "type": "CONDITIONING", "link": 81}, {"name": "vae", "type": "VAE", "link": 82}, {"name": "pixels", "type": "IMAGE", "link": 97}, {"name": "mask", "type": "MASK", "link": 98}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [77], "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [78], "slot_index": 1}, {"name": "latent", "type": "LATENT", "links": [88], "slot_index": 2}], "properties": {"Node name for S&R": "InpaintModelConditioning"}, "widgets_values": [false]}, {"id": 44, "type": "ImagePadForOutpaint", "pos": [415, 359], "size": [315, 174], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 96}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [97], "slot_index": 0}, {"name": "MASK", "type": "MASK", "links": [98], "slot_index": 1}], "properties": {"Node name for S&R": "ImagePadForOutpaint"}, "widgets_values": [400, 0, 400, 400, 24]}, {"id": 23, "type": "CLIPTextEncode", "pos": [144, -7], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 62}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["beautiful scenery"], "color": "#232", "bgcolor": "#353"}, {"id": 9, "type": "SaveImage", "pos": [1877, 101], "size": [828.9535522460938, 893.8475341796875], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 95}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 3, "type": "KSampler", "pos": [1280, 100], "size": [315, 262], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 86}, {"name": "positive", "type": "CONDITIONING", "link": 77}, {"name": "negative", "type": "CONDITIONING", "link": 78}, {"name": "latent_image", "type": "LATENT", "link": 88}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [7], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [164211176398261, "randomize", 20, 1, "euler", "normal", 1]}, {"id": 17, "type": "LoadImage", "pos": [23, 376], "size": [315, 314.0000305175781], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [96], "slot_index": 0, "shape": 3}, {"name": "MASK", "type": "MASK", "links": [], "slot_index": 1, "shape": 3}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["sd3_controlnet_example.png", "image"]}, {"id": 31, "type": "UNETLoader", "pos": [602, -120], "size": [315, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [85], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-fill-dev.safetensors", "default"]}], "links": [[7, 3, 0, 8, 0, "LATENT"], [41, 23, 0, 26, 0, "CONDITIONING"], [60, 32, 0, 8, 1, "VAE"], [62, 34, 0, 23, 0, "CLIP"], [63, 34, 0, 7, 0, "CLIP"], [77, 38, 0, 3, 1, "CONDITIONING"], [78, 38, 1, 3, 2, "CONDITIONING"], [80, 26, 0, 38, 0, "CONDITIONING"], [81, 7, 0, 38, 1, "CONDITIONING"], [82, 32, 0, 38, 2, "VAE"], [85, 31, 0, 39, 0, "MODEL"], [86, 39, 0, 3, 0, "MODEL"], [88, 38, 2, 3, 3, "LATENT"], [95, 8, 0, 9, 0, "IMAGE"], [96, 17, 0, 44, 0, "IMAGE"], [97, 44, 0, 38, 3, "IMAGE"], [98, 44, 1, 38, 4, "MASK"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1, "offset": [240.63601442156687, 211.86992742998336]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_kontext_example.png", "prompt": {"6": {"inputs": {"text": "the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwitch beside a beautiful alpine lake", "clip": ["11", 0]}, "class_type": "CLIPTextEncode", "_meta": {"title": "CLIP Text Encode (Positive Prompt)"}}, "8": {"inputs": {"samples": ["13", 0], "vae": ["10", 0]}, "class_type": "VAEDecode", "_meta": {"title": "VAE Decode"}}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage", "_meta": {"title": "Save Image"}}, "10": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}}, "11": {"inputs": {"clip_name1": "t5xxl_fp16.safetensors", "clip_name2": "clip_l.safetensors", "type": "flux", "device": "default"}, "class_type": "DualCLIPLoader", "_meta": {"title": "DualCLIPLoader"}}, "12": {"inputs": {"unet_name": "flux1-kontext-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader", "_meta": {"title": "Load Diffusion Model"}}, "13": {"inputs": {"noise": ["25", 0], "guider": ["22", 0], "sampler": ["16", 0], "sigmas": ["17", 0], "latent_image": ["27", 0]}, "class_type": "SamplerCustomAdvanced", "_meta": {"title": "SamplerCustomAdvanced"}}, "16": {"inputs": {"sampler_name": "euler"}, "class_type": "KSamplerSelect", "_meta": {"title": "KSamplerSelect"}}, "17": {"inputs": {"scheduler": "simple", "steps": 20, "denoise": 1.0, "model": ["30", 0]}, "class_type": "BasicScheduler", "_meta": {"title": "BasicScheduler"}}, "22": {"inputs": {"model": ["30", 0], "conditioning": ["42", 0]}, "class_type": "BasicGuider", "_meta": {"title": "BasicGuider"}}, "25": {"inputs": {"noise_seed": 679064953796969}, "class_type": "RandomNoise", "_meta": {"title": "RandomNoise"}}, "26": {"inputs": {"guidance": 2.5, "conditioning": ["6", 0]}, "class_type": "FluxGuidance", "_meta": {"title": "FluxGuidance"}}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage", "_meta": {"title": "EmptySD3LatentImage"}}, "30": {"inputs": {"max_shift": 1.15, "base_shift": 0.5, "width": 1024, "height": 1024, "model": ["12", 0]}, "class_type": "ModelSamplingFlux", "_meta": {"title": "ModelSamplingFlux"}}, "39": {"inputs": {"pixels": ["40", 0], "vae": ["10", 0]}, "class_type": "VAEEncode", "_meta": {"title": "VAE Encode"}}, "40": {"inputs": {"image": ["41", 0]}, "class_type": "FluxKontextImageScale", "_meta": {"title": "FluxKontextImageScale"}}, "41": {"inputs": {"image": "fennec_girl_sing.png"}, "class_type": "LoadImage", "_meta": {"title": "Load Image"}, "is_changed": ["8da6d35e6206689be1ac0d44e693a7eb13babffda52318c7a99b4f03cc8aa773"]}, "42": {"inputs": {"conditioning": ["26", 0], "latent": ["39", 0]}, "class_type": "ReferenceLatent", "_meta": {"title": "ReferenceLatent"}}}, "workflow": {"id": "ad18abd3-bdee-4f80-8fae-d15d4f845b9d", "revision": 0, "last_node_id": 58, "last_link_id": 158, "nodes": [{"id": 11, "type": "DualCLIPLoader", "pos": [48, 288], "size": [315, 130], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "slot_index": 0, "links": [10]}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux", "default"]}, {"id": 17, "type": "BasicScheduler", "pos": [480, 1008], "size": [315, 106], "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 55}], "outputs": [{"name": "SIGMAS", "type": "SIGMAS", "links": [20]}], "properties": {"Node name for S&R": "BasicScheduler"}, "widgets_values": ["simple", 20, 1]}, {"id": 16, "type": "KSamplerSelect", "pos": [480, 912], "size": [315, 58], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "SAMPLER", "type": "SAMPLER", "links": [19]}], "properties": {"Node name for S&R": "KSamplerSelect"}, "widgets_values": ["euler"]}, {"id": 8, "type": "VAEDecode", "pos": [866, 367], "size": [210, 46], "flags": {}, "order": 21, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 24}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [9]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 30, "type": "ModelSamplingFlux", "pos": [480, 1152], "size": [315, 130], "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 56}, {"name": "width", "type": "INT", "widget": {"name": "width"}, "link": 115}, {"name": "height", "type": "INT", "widget": {"name": "height"}, "link": 114}], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [54, 55]}], "properties": {"Node name for S&R": "ModelSamplingFlux"}, "widgets_values": [1.15, 0.5, 1024, 1024]}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [480, 624], "size": [315, 106], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "width", "type": "INT", "widget": {"name": "width"}, "link": 112}, {"name": "height", "type": "INT", "widget": {"name": "height"}, "link": 113}], "outputs": [{"name": "LATENT", "type": "LATENT", "slot_index": 0, "links": [116]}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 34, "type": "PrimitiveNode", "pos": [432, 480], "size": [210, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "INT", "type": "INT", "widget": {"name": "width"}, "slot_index": 0, "links": [112, 115]}], "title": "width", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 35, "type": "PrimitiveNode", "pos": [672, 480], "size": [210, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "INT", "type": "INT", "widget": {"name": "height"}, "slot_index": 0, "links": [113, 114]}], "title": "height", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 9, "type": "SaveImage", "pos": [1155, 196], "size": [985.3012084960938, 1060.3828125], "flags": {}, "order": 22, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 37, "type": "Note", "pos": [480, 1344], "size": [314.99755859375, 117.98363494873047], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [], "properties": {"text": ""}, "widgets_values": ["The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\n"], "color": "#432", "bgcolor": "#653"}, {"id": 26, "type": "FluxGuidance", "pos": [480, 144], "size": [317.4000244140625, 58], "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [123]}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [2.5], "color": "#233", "bgcolor": "#355"}, {"id": 10, "type": "VAELoader", "pos": [50.72727584838867, 466.54541015625], "size": [311.81634521484375, 60.429901123046875], "flags": {}, "order": 5, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [12, 120]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 13, "type": "SamplerCustomAdvanced", "pos": [864, 192], "size": [272.3617858886719, 124.53733825683594], "flags": {}, "order": 20, "mode": 0, "inputs": [{"name": "noise", "type": "NOISE", "link": 37}, {"name": "guider", "type": "GUIDER", "link": 30}, {"name": "sampler", "type": "SAMPLER", "link": 19}, {"name": "sigmas", "type": "SIGMAS", "link": 20}, {"name": "latent_image", "type": "LATENT", "link": 116}], "outputs": [{"name": "output", "type": "LATENT", "slot_index": 0, "links": [24]}, {"name": "denoised_output", "type": "LATENT", "links": null}], "properties": {"Node name for S&R": "SamplerCustomAdvanced"}, "widgets_values": []}, {"id": 39, "type": "VAEEncode", "pos": [501.1323547363281, -12.391702651977539], "size": [140, 46], "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "pixels", "type": "IMAGE", "link": 143}, {"name": "vae", "type": "VAE", "link": 120}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [138]}], "properties": {"Node name for S&R": "VAEEncode"}, "widgets_values": []}, {"id": 42, "type": "ReferenceLatent", "pos": [676.4634399414062, -28.66999626159668], "size": [197.712890625, 46], "flags": {}, "order": 18, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 123}, {"name": "latent", "shape": 7, "type": "LATENT", "link": 138}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [157]}], "properties": {"Node name for S&R": "ReferenceLatent"}, "widgets_values": []}, {"id": 22, "type": "BasicGuider", "pos": [887.5904541015625, 60.72023010253906], "size": [222.3482666015625, 46], "flags": {}, "order": 19, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 54}, {"name": "conditioning", "type": "CONDITIONING", "link": 157}], "outputs": [{"name": "GUIDER", "type": "GUIDER", "slot_index": 0, "links": [30]}], "properties": {"Node name for S&R": "BasicGuider"}, "widgets_values": []}, {"id": 53, "type": "ImageScaleBy", "pos": [249.71116638183594, -83.57847595214844], "size": [210, 82], "flags": {}, "order": 15, "mode": 4, "inputs": [{"name": "image", "type": "IMAGE", "link": 142}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [143]}], "properties": {"Node name for S&R": "ImageScaleBy"}, "widgets_values": ["area", 0.5000000000000001]}, {"id": 40, "type": "FluxKontextImageScale", "pos": [43.59303665161133, -83.14352416992188], "size": [187.75448608398438, 26], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "image", "type": "IMAGE", "link": 158}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [142]}], "properties": {"Node name for S&R": "FluxKontextImageScale"}, "widgets_values": []}, {"id": 41, "type": "LoadImage", "pos": [-274.419921875, -82.92684936523438], "size": [274.080078125, 314], "flags": {}, "order": 6, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [158]}, {"name": "MASK", "type": "MASK", "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["fennec_girl_sing.png", "image"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 240], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 10}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [41]}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwitch beside a beautiful alpine lake"], "color": "#232", "bgcolor": "#353"}, {"id": 25, "type": "RandomNoise", "pos": [480, 768], "size": [315, 82], "flags": {}, "order": 7, "mode": 0, "inputs": [], "outputs": [{"name": "NOISE", "type": "NOISE", "links": [37]}], "properties": {"Node name for S&R": "RandomNoise"}, "widgets_values": [679064953796969, "randomize"], "color": "#2a363b", "bgcolor": "#3f5159"}, {"id": 12, "type": "UNETLoader", "pos": [48, 144], "size": [315, 82], "flags": {}, "order": 8, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [56]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-kontext-dev.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 28, "type": "Note", "pos": [48, 576], "size": [336, 288], "flags": {}, "order": 9, "mode": 0, "inputs": [], "outputs": [], "properties": {"text": ""}, "widgets_values": ["If you get an error in any of the nodes above make sure the files are in the correct directories.\n\nSee the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\n\nflux1-kontext-dev.safetensors goes in: ComfyUI/models/unet/\n\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\n\nae.safetensors goes in: ComfyUI/models/vae/\n\n\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues."], "color": "#432", "bgcolor": "#653"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [10, 11, 0, 6, 0, "CLIP"], [12, 10, 0, 8, 1, "VAE"], [19, 16, 0, 13, 2, "SAMPLER"], [20, 17, 0, 13, 3, "SIGMAS"], [24, 13, 0, 8, 0, "LATENT"], [30, 22, 0, 13, 1, "GUIDER"], [37, 25, 0, 13, 0, "NOISE"], [41, 6, 0, 26, 0, "CONDITIONING"], [54, 30, 0, 22, 0, "MODEL"], [55, 30, 0, 17, 0, "MODEL"], [56, 12, 0, 30, 0, "MODEL"], [112, 34, 0, 27, 0, "INT"], [113, 35, 0, 27, 1, "INT"], [114, 35, 0, 30, 2, "INT"], [115, 34, 0, 30, 1, "INT"], [116, 27, 0, 13, 4, "LATENT"], [120, 10, 0, 39, 1, "VAE"], [123, 26, 0, 42, 0, "CONDITIONING"], [138, 39, 0, 42, 1, "LATENT"], [142, 40, 0, 53, 0, "IMAGE"], [143, 53, 0, 39, 0, "IMAGE"], [157, 42, 0, 22, 1, "CONDITIONING"], [158, 41, 0, 40, 0, "IMAGE"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.7513148009015777, "offset": [394.60980361321964, 211.4005936883544]}, "frontendVersion": "1.21.7", "groupNodes": {"EmptyLatentImage": {"nodes": [{"type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 0}, {"type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 1}, {"type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": null, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": null, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "index": 2}], "links": [[1, 0, 2, 0, 34, "INT"], [0, 0, 2, 1, 35, "INT"]], "external": [[0, 0, "INT"], [1, 0, "INT"], [2, 0, "LATENT"]], "config": {"0": {"output": {"0": {"name": "height"}}, "input": {"value": {"visible": true}}}, "1": {"output": {"0": {"name": "width"}}, "input": {"value": {"visible": true}}}, "2": {"input": {"width": {"visible": false}, "height": {"visible": false}}}}}}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_redux_model_example.png", "prompt": {"6": {"inputs": {"text": "cute anime girl with massive fluffy fennec ears", "clip": ["11", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["13", 0], "vae": ["10", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "10": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "11": {"inputs": {"clip_name1": "t5xxl_fp16.safetensors", "clip_name2": "clip_l.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "12": {"inputs": {"unet_name": "flux1-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "13": {"inputs": {"noise": ["25", 0], "guider": ["22", 0], "sampler": ["16", 0], "sigmas": ["17", 0], "latent_image": ["27", 0]}, "class_type": "SamplerCustomAdvanced"}, "16": {"inputs": {"sampler_name": "euler"}, "class_type": "KSamplerSelect"}, "17": {"inputs": {"scheduler": "simple", "steps": 20, "denoise": 1.0, "model": ["30", 0]}, "class_type": "BasicScheduler"}, "22": {"inputs": {"model": ["30", 0], "conditioning": ["41", 0]}, "class_type": "BasicGuider"}, "25": {"inputs": {"noise_seed": 958831004022715}, "class_type": "RandomNoise"}, "26": {"inputs": {"guidance": 3.5, "conditioning": ["6", 0]}, "class_type": "FluxGuidance"}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}, "30": {"inputs": {"max_shift": 1.15, "base_shift": 0.5, "width": 1024, "height": 1024, "model": ["12", 0]}, "class_type": "ModelSamplingFlux"}, "38": {"inputs": {"clip_name": "sigclip_vision_patch14_384.safetensors"}, "class_type": "CLIPVisionLoader"}, "39": {"inputs": {"clip_vision": ["38", 0], "image": ["40", 0]}, "class_type": "CLIPVisionEncode"}, "40": {"inputs": {"image": "sd3_controlnet_example.png", "upload": "image"}, "class_type": "LoadImage", "is_changed": ["9d64e7ed10ee150e1d04938e57500fd889ff0413372ee67abf27a6d197af4d48"]}, "41": {"inputs": {"conditioning": ["26", 0], "style_model": ["42", 0], "clip_vision_output": ["39", 0]}, "class_type": "StyleModelApply"}, "42": {"inputs": {"style_model_name": "flux1-redux-dev.safetensors"}, "class_type": "StyleModelLoader"}}, "workflow": {"last_node_id": 43, "last_link_id": 123, "nodes": [{"id": 11, "type": "DualCLIPLoader", "pos": [48, 288], "size": [315, 106], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [10], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux"]}, {"id": 17, "type": "BasicScheduler", "pos": [480, 1008], "size": [315, 106], "flags": {}, "order": 18, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 55, "slot_index": 0}], "outputs": [{"name": "SIGMAS", "type": "SIGMAS", "links": [20], "shape": 3}], "properties": {"Node name for S&R": "BasicScheduler"}, "widgets_values": ["simple", 20, 1]}, {"id": 16, "type": "KSamplerSelect", "pos": [480, 912], "size": [315, 58], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "SAMPLER", "type": "SAMPLER", "links": [19], "shape": 3}], "properties": {"Node name for S&R": "KSamplerSelect"}, "widgets_values": ["euler"]}, {"id": 26, "type": "FluxGuidance", "pos": [480, 144], "size": [317.4000244140625, 58], "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [122], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [3.5], "color": "#233", "bgcolor": "#355"}, {"id": 13, "type": "SamplerCustomAdvanced", "pos": [864, 192], "size": [272.3617858886719, 124.53733825683594], "flags": {}, "order": 21, "mode": 0, "inputs": [{"name": "noise", "type": "NOISE", "link": 37, "slot_index": 0}, {"name": "guider", "type": "GUIDER", "link": 30, "slot_index": 1}, {"name": "sampler", "type": "SAMPLER", "link": 19, "slot_index": 2}, {"name": "sigmas", "type": "SIGMAS", "link": 20, "slot_index": 3}, {"name": "latent_image", "type": "LATENT", "link": 116, "slot_index": 4}], "outputs": [{"name": "output", "type": "LATENT", "links": [24], "slot_index": 0, "shape": 3}, {"name": "denoised_output", "type": "LATENT", "links": null, "shape": 3}], "properties": {"Node name for S&R": "SamplerCustomAdvanced"}, "widgets_values": []}, {"id": 25, "type": "RandomNoise", "pos": [480, 768], "size": [315, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "NOISE", "type": "NOISE", "links": [37], "shape": 3}], "properties": {"Node name for S&R": "RandomNoise"}, "widgets_values": [958831004022715, "randomize"], "color": "#2a363b", "bgcolor": "#3f5159"}, {"id": 8, "type": "VAEDecode", "pos": [866, 367], "size": [210, 46], "flags": {}, "order": 22, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 24}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 30, "type": "ModelSamplingFlux", "pos": [480, 1152], "size": [315, 130], "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 56, "slot_index": 0}, {"name": "width", "type": "INT", "link": 115, "slot_index": 1, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": 114, "slot_index": 2, "widget": {"name": "height"}}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [54, 55], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "ModelSamplingFlux"}, "widgets_values": [1.15, 0.5, 1024, 1024]}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [480, 624], "size": [315, 106], "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": 112, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": 113, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [116], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 34, "type": "PrimitiveNode", "pos": [432, 480], "size": [210, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "INT", "type": "INT", "links": [112, 115], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 35, "type": "PrimitiveNode", "pos": [672, 480], "size": [210, 82], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "INT", "type": "INT", "links": [113, 114], "slot_index": 0, "widget": {"name": "height"}}], "title": "height", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 12, "type": "UNETLoader", "pos": [48, 144], "size": [315, 82], "flags": {}, "order": 5, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [56], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-dev.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 9, "type": "SaveImage", "pos": [1155, 196], "size": [985.3012084960938, 1060.3828125], "flags": {}, "order": 23, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 37, "type": "Note", "pos": [480, 1344], "size": [314.99755859375, 117.98363494873047], "flags": {}, "order": 6, "mode": 0, "inputs": [], "outputs": [], "properties": {"text": ""}, "widgets_values": ["The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\n"], "color": "#432", "bgcolor": "#653"}, {"id": 10, "type": "VAELoader", "pos": [48, 432], "size": [311.81634521484375, 60.429901123046875], "flags": {}, "order": 7, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [12], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 28, "type": "Note", "pos": [48, 576], "size": [336, 288], "flags": {}, "order": 8, "mode": 0, "inputs": [], "outputs": [], "properties": {"text": ""}, "widgets_values": ["If you get an error in any of the nodes above make sure the files are in the correct directories.\n\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\n\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\n\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\n\nae.safetensors goes in: ComfyUI/models/vae/\n\n\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues."], "color": "#432", "bgcolor": "#653"}, {"id": 39, "type": "CLIPVisionEncode", "pos": [420, -300], "size": [290, 50], "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "clip_vision", "type": "CLIP_VISION", "link": 117}, {"name": "image", "type": "IMAGE", "link": 118}], "outputs": [{"name": "CLIP_VISION_OUTPUT", "type": "CLIP_VISION_OUTPUT", "links": [120], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionEncode"}}, {"id": 40, "type": "LoadImage", "pos": [60, -300], "size": [315, 314], "flags": {}, "order": 9, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [118]}, {"name": "MASK", "type": "MASK", "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["sd3_controlnet_example.png", "image"]}, {"id": 42, "type": "StyleModelLoader", "pos": [400, -180], "size": [340, 60], "flags": {}, "order": 10, "mode": 0, "inputs": [], "outputs": [{"name": "STYLE_MODEL", "type": "STYLE_MODEL", "links": [119]}], "properties": {"Node name for S&R": "StyleModelLoader"}, "widgets_values": ["flux1-redux-dev.safetensors"]}, {"id": 38, "type": "CLIPVisionLoader", "pos": [60, -410], "size": [370, 60], "flags": {}, "order": 11, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [117], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["sigclip_vision_patch14_384.safetensors"]}, {"id": 41, "type": "StyleModelApply", "pos": [760, -300], "size": [320, 70], "flags": {}, "order": 19, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 122}, {"name": "style_model", "type": "STYLE_MODEL", "link": 119}, {"name": "clip_vision_output", "type": "CLIP_VISION_OUTPUT", "link": 120, "shape": 7}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [123], "slot_index": 0}], "properties": {"Node name for S&R": "StyleModelApply"}}, {"id": 22, "type": "BasicGuider", "pos": [960, 66], "size": [222.3482666015625, 46], "flags": {}, "order": 20, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 54, "slot_index": 0}, {"name": "conditioning", "type": "CONDITIONING", "link": 123, "slot_index": 1}], "outputs": [{"name": "GUIDER", "type": "GUIDER", "links": [30], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "BasicGuider"}, "widgets_values": []}, {"id": 43, "type": "Note", "pos": [1130, -440], "size": [345.9017028808594, 182.3145294189453], "flags": {}, "order": 12, "mode": 0, "inputs": [], "outputs": [], "properties": {}, "widgets_values": ["The redux model lets you prompt with images. It can be used with any Flux1 dev or schnell model workflow.\n\nYou can chain multiple \"Apply Style Model\" nodes if you want to mix multiple images together."], "color": "#432", "bgcolor": "#653"}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 240], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 10}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["cute anime girl with massive fluffy fennec ears"], "color": "#232", "bgcolor": "#353"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [10, 11, 0, 6, 0, "CLIP"], [12, 10, 0, 8, 1, "VAE"], [19, 16, 0, 13, 2, "SAMPLER"], [20, 17, 0, 13, 3, "SIGMAS"], [24, 13, 0, 8, 0, "LATENT"], [30, 22, 0, 13, 1, "GUIDER"], [37, 25, 0, 13, 0, "NOISE"], [41, 6, 0, 26, 0, "CONDITIONING"], [54, 30, 0, 22, 0, "MODEL"], [55, 30, 0, 17, 0, "MODEL"], [56, 12, 0, 30, 0, "MODEL"], [112, 34, 0, 27, 0, "INT"], [113, 35, 0, 27, 1, "INT"], [114, 35, 0, 30, 2, "INT"], [115, 34, 0, 30, 1, "INT"], [116, 27, 0, 13, 4, "LATENT"], [117, 38, 0, 39, 0, "CLIP_VISION"], [118, 40, 0, 39, 1, "IMAGE"], [119, 42, 0, 41, 1, "STYLE_MODEL"], [120, 39, 0, 41, 2, "CLIP_VISION_OUTPUT"], [122, 26, 0, 41, 0, "CONDITIONING"], [123, 41, 0, 22, 1, "CONDITIONING"]], "groups": [{"id": 1, "title": "Redux Model", "bounding": [50, -483.6000061035156, 1040, 507.6000061035156], "color": "#3f789e", "font_size": 24, "flags": {}}], "config": {}, "extra": {"ds": {"scale": 1.1, "offset": [-21.145284503399942, 502.89633943324753]}, "groupNodes": {"EmptyLatentImage": {"nodes": [{"type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 0}, {"type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 1}, {"type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": null, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": null, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "index": 2}], "links": [[1, 0, 2, 0, 34, "INT"], [0, 0, 2, 1, 35, "INT"]], "external": [[0, 0, "INT"], [1, 0, "INT"], [2, 0, "LATENT"]], "config": {"0": {"output": {"0": {"name": "height"}}, "input": {"value": {"visible": true}}}, "1": {"output": {"0": {"name": "width"}}, "input": {"value": {"visible": true}}}, "2": {"input": {"width": {"visible": false}, "height": {"visible": false}}}}}}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_schnell_checkpoint_example.png", "prompt": {"6": {"inputs": {"text": "a bottle with a beautiful rainbow galaxy inside it on top of a wooden table in the middle of a modern kitchen beside a plate of vegetables and mushrooms and a wine glasse that contains a planet earth with a plate with a half eaten apple pie on it", "clip": ["30", 1]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["31", 0], "vae": ["30", 2]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}, "30": {"inputs": {"ckpt_name": "flux1-schnell-fp8.safetensors"}, "class_type": "CheckpointLoaderSimple"}, "31": {"inputs": {"seed": 173805153958730, "steps": 4, "cfg": 1.0, "sampler_name": "euler", "scheduler": "simple", "denoise": 1.0, "model": ["30", 0], "positive": ["6", 0], "negative": ["33", 0], "latent_image": ["27", 0]}, "class_type": "KSampler"}, "33": {"inputs": {"text": "", "clip": ["30", 1]}, "class_type": "CLIPTextEncode"}}, "workflow": {"last_node_id": 36, "last_link_id": 58, "nodes": [{"id": 33, "type": "CLIPTextEncode", "pos": [390, 400], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {"collapsed": true}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 54, "slot_index": 0}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [55], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [471, 455], "size": {"0": 315, "1": 106}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [51], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "color": "#323", "bgcolor": "#535"}, {"id": 8, "type": "VAEDecode", "pos": [1151, 195], "size": {"0": 210, "1": 46}, "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 52}, {"name": "vae", "type": "VAE", "link": 46}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 9, "type": "SaveImage", "pos": [1375, 194], "size": {"0": 985.3012084960938, "1": 1060.3828125}, "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 31, "type": "KSampler", "pos": [816, 192], "size": {"0": 315, "1": 262}, "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 47}, {"name": "positive", "type": "CONDITIONING", "link": 58}, {"name": "negative", "type": "CONDITIONING", "link": 55}, {"name": "latent_image", "type": "LATENT", "link": 51}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [52], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [173805153958730, "randomize", 4, 1, "euler", "simple", 1]}, {"id": 30, "type": "CheckpointLoaderSimple", "pos": [48, 192], "size": {"0": 315, "1": 98}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [47], "shape": 3, "slot_index": 0}, {"name": "CLIP", "type": "CLIP", "links": [45, 54], "shape": 3, "slot_index": 1}, {"name": "VAE", "type": "VAE", "links": [46], "shape": 3, "slot_index": 2}], "properties": {"Node name for S&R": "CheckpointLoaderSimple"}, "widgets_values": ["flux1-schnell-fp8.safetensors"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 192], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 3, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 45}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [58], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a bottle with a beautiful rainbow galaxy inside it on top of a wooden table in the middle of a modern kitchen beside a plate of vegetables and mushrooms and a wine glasse that contains a planet earth with a plate with a half eaten apple pie on it"], "color": "#232", "bgcolor": "#353"}, {"id": 34, "type": "Note", "pos": [831, 501], "size": {"0": 282.8617858886719, "1": 164.08004760742188}, "flags": {}, "order": 2, "mode": 0, "properties": {"text": ""}, "widgets_values": ["Note that Flux dev and schnell do not have any negative prompt so CFG should be set to 1.0. Setting CFG to 1.0 means the negative prompt is ignored.\n\nThe schnell model is a distilled model that can generate a good image with only 4 steps."], "color": "#432", "bgcolor": "#653"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [45, 30, 1, 6, 0, "CLIP"], [46, 30, 2, 8, 1, "VAE"], [47, 30, 0, 31, 0, "MODEL"], [51, 27, 0, 31, 3, "LATENT"], [52, 31, 0, 8, 0, "LATENT"], [54, 30, 1, 33, 0, "CLIP"], [55, 33, 0, 31, 2, "CONDITIONING"], [58, 6, 0, 31, 1, "CONDITIONING"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.1, "offset": [0.6836674124529055, 1.8290357611967831]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/flux_schnell_example.png", "prompt": {"5": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptyLatentImage"}, "6": {"inputs": {"text": "a bottle with a beautiful rainbow galaxy inside it on top of a wooden table in the middle of a modern kitchen beside a plate of vegetables and mushrooms and a wine glasse that contains a planet earth with a plate with a half eaten apple pie on it", "clip": ["11", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["13", 0], "vae": ["10", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "10": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "11": {"inputs": {"clip_name1": "t5xxl_fp16.safetensors", "clip_name2": "clip_l.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "12": {"inputs": {"unet_name": "flux1-schnell.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "13": {"inputs": {"noise": ["25", 0], "guider": ["22", 0], "sampler": ["16", 0], "sigmas": ["17", 0], "latent_image": ["5", 0]}, "class_type": "SamplerCustomAdvanced"}, "16": {"inputs": {"sampler_name": "euler"}, "class_type": "KSamplerSelect"}, "17": {"inputs": {"scheduler": "simple", "steps": 4, "denoise": 1.0, "model": ["12", 0]}, "class_type": "BasicScheduler"}, "22": {"inputs": {"model": ["12", 0], "conditioning": ["6", 0]}, "class_type": "BasicGuider"}, "25": {"inputs": {"noise_seed": 112298569477003}, "class_type": "RandomNoise"}}, "workflow": {"last_node_id": 27, "last_link_id": 40, "nodes": [{"id": 13, "type": "SamplerCustomAdvanced", "pos": [842, 215], "size": {"0": 355.20001220703125, "1": 106}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "noise", "type": "NOISE", "link": 37, "slot_index": 0}, {"name": "guider", "type": "GUIDER", "link": 30, "slot_index": 1}, {"name": "sampler", "type": "SAMPLER", "link": 19, "slot_index": 2}, {"name": "sigmas", "type": "SIGMAS", "link": 20, "slot_index": 3}, {"name": "latent_image", "type": "LATENT", "link": 23, "slot_index": 4}], "outputs": [{"name": "output", "type": "LATENT", "links": [24], "shape": 3, "slot_index": 0}, {"name": "denoised_output", "type": "LATENT", "links": null, "shape": 3}], "properties": {"Node name for S&R": "SamplerCustomAdvanced"}}, {"id": 8, "type": "VAEDecode", "pos": [1248, 192], "size": {"0": 210, "1": 46}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 24}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 10, "type": "VAELoader", "pos": [48, 384], "size": {"0": 315, "1": 58}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [12], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 11, "type": "DualCLIPLoader", "pos": [48, 240], "size": {"0": 315, "1": 106}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "CLIP", "type": "CLIP", "links": [10], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux"]}, {"id": 12, "type": "UNETLoader", "pos": [48, 96], "size": {"0": 315, "1": 82}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [38, 39], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-schnell.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 26, "type": "Note", "pos": [48, 480], "size": {"0": 336, "1": 288}, "flags": {}, "order": 3, "mode": 0, "properties": {"text": ""}, "widgets_values": ["If you get an error in any of the nodes above make sure the files are in the correct directories.\n\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\n\nflux1-schnell.safetensors goes in: ComfyUI/models/unet/\n\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\n\nae.safetensors goes in: ComfyUI/models/vae/\n\n\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues."], "color": "#432", "bgcolor": "#653"}, {"id": 22, "type": "BasicGuider", "pos": [559, 125], "size": {"0": 241.79998779296875, "1": 46}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 39, "slot_index": 0}, {"name": "conditioning", "type": "CONDITIONING", "link": 40, "slot_index": 1}], "outputs": [{"name": "GUIDER", "type": "GUIDER", "links": [30], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "BasicGuider"}}, {"id": 5, "type": "EmptyLatentImage", "pos": [480, 432], "size": {"0": 315, "1": 106}, "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "LATENT", "type": "LATENT", "links": [23], "slot_index": 0}], "properties": {"Node name for S&R": "EmptyLatentImage"}, "widgets_values": [1024, 1024, 1], "color": "#323", "bgcolor": "#535"}, {"id": 25, "type": "RandomNoise", "pos": [480, 576], "size": {"0": 315, "1": 82}, "flags": {}, "order": 5, "mode": 0, "outputs": [{"name": "NOISE", "type": "NOISE", "links": [37], "shape": 3}], "properties": {"Node name for S&R": "RandomNoise"}, "widgets_values": [112298569477003, "randomize"], "color": "#2a363b", "bgcolor": "#3f5159"}, {"id": 16, "type": "KSamplerSelect", "pos": [480, 720], "size": {"0": 315, "1": 58}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "SAMPLER", "type": "SAMPLER", "links": [19], "shape": 3}], "properties": {"Node name for S&R": "KSamplerSelect"}, "widgets_values": ["euler"]}, {"id": 17, "type": "BasicScheduler", "pos": [480, 816], "size": {"0": 315, "1": 106}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 38, "slot_index": 0}], "outputs": [{"name": "SIGMAS", "type": "SIGMAS", "links": [20], "shape": 3}], "properties": {"Node name for S&R": "BasicScheduler"}, "widgets_values": ["simple", 4, 1]}, {"id": 27, "type": "Note", "pos": [480, 960], "size": {"0": 311.3529052734375, "1": 131.16229248046875}, "flags": {}, "order": 7, "mode": 0, "properties": {"text": ""}, "widgets_values": ["The schnell model is a distilled model that can generate a good image with only 4 steps."], "color": "#432", "bgcolor": "#653"}, {"id": 9, "type": "SaveImage", "pos": [1488, 192], "size": {"0": 985.3012084960938, "1": 1060.3828125}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [375, 221], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 10}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [40], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a bottle with a beautiful rainbow galaxy inside it on top of a wooden table in the middle of a modern kitchen beside a plate of vegetables and mushrooms and a wine glasse that contains a planet earth with a plate with a half eaten apple pie on it"], "color": "#232", "bgcolor": "#353"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [10, 11, 0, 6, 0, "CLIP"], [12, 10, 0, 8, 1, "VAE"], [19, 16, 0, 13, 2, "SAMPLER"], [20, 17, 0, 13, 3, "SIGMAS"], [23, 5, 0, 13, 4, "LATENT"], [24, 13, 0, 8, 0, "LATENT"], [30, 22, 0, 13, 1, "GUIDER"], [37, 25, 0, 13, 0, "NOISE"], [38, 12, 0, 17, 0, "MODEL"], [39, 12, 0, 22, 0, "MODEL"], [40, 6, 0, 22, 1, "CONDITIONING"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.9090909090909091, "offset": [3.4414091410193346, -8.568185703424684]}}, "version": 0.4}}, {"source": "image-metadata", "image": "flux/girl_in_field.png", "prompt": {"6": {"inputs": {"text": "mulan standing in front of a rice paddy", "clip": ["11", 0]}, "class_type": "CLIPTextEncode"}, "8": {"inputs": {"samples": ["13", 0], "vae": ["10", 0]}, "class_type": "VAEDecode"}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage"}, "10": {"inputs": {"vae_name": "ae.safetensors"}, "class_type": "VAELoader"}, "11": {"inputs": {"clip_name1": "t5xxl_fp16.safetensors", "clip_name2": "clip_l.safetensors", "type": "flux"}, "class_type": "DualCLIPLoader"}, "12": {"inputs": {"unet_name": "flux1-dev.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader"}, "13": {"inputs": {"noise": ["25", 0], "guider": ["22", 0], "sampler": ["16", 0], "sigmas": ["17", 0], "latent_image": ["27", 0]}, "class_type": "SamplerCustomAdvanced"}, "16": {"inputs": {"sampler_name": "euler"}, "class_type": "KSamplerSelect"}, "17": {"inputs": {"scheduler": "simple", "steps": 20, "denoise": 1.0, "model": ["30", 0]}, "class_type": "BasicScheduler"}, "22": {"inputs": {"model": ["30", 0], "conditioning": ["26", 0]}, "class_type": "BasicGuider"}, "25": {"inputs": {"noise_seed": 219670278747233}, "class_type": "RandomNoise"}, "26": {"inputs": {"guidance": 3.5, "conditioning": ["6", 0]}, "class_type": "FluxGuidance"}, "27": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage"}, "30": {"inputs": {"max_shift": 1.15, "base_shift": 0.5, "width": 1024, "height": 1024, "model": ["12", 0]}, "class_type": "ModelSamplingFlux"}}, "workflow": {"last_node_id": 37, "last_link_id": 116, "nodes": [{"id": 17, "type": "BasicScheduler", "pos": [480, 1008], "size": {"0": 315, "1": 106}, "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 55, "slot_index": 0}], "outputs": [{"name": "SIGMAS", "type": "SIGMAS", "links": [20], "shape": 3}], "properties": {"Node name for S&R": "BasicScheduler"}, "widgets_values": ["simple", 20, 1]}, {"id": 16, "type": "KSamplerSelect", "pos": [480, 912], "size": {"0": 315, "1": 58}, "flags": {}, "order": 0, "mode": 0, "outputs": [{"name": "SAMPLER", "type": "SAMPLER", "links": [19], "shape": 3}], "properties": {"Node name for S&R": "KSamplerSelect"}, "widgets_values": ["euler"]}, {"id": 26, "type": "FluxGuidance", "pos": [480, 144], "size": {"0": 317.4000244140625, "1": 58}, "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "conditioning", "type": "CONDITIONING", "link": 41}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [42], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "FluxGuidance"}, "widgets_values": [3.5], "color": "#233", "bgcolor": "#355"}, {"id": 22, "type": "BasicGuider", "pos": [576, 48], "size": {"0": 222.3482666015625, "1": 46}, "flags": {}, "order": 14, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 54, "slot_index": 0}, {"name": "conditioning", "type": "CONDITIONING", "link": 42, "slot_index": 1}], "outputs": [{"name": "GUIDER", "type": "GUIDER", "links": [30], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "BasicGuider"}}, {"id": 13, "type": "SamplerCustomAdvanced", "pos": [864, 192], "size": {"0": 272.3617858886719, "1": 124.53733825683594}, "flags": {}, "order": 15, "mode": 0, "inputs": [{"name": "noise", "type": "NOISE", "link": 37, "slot_index": 0}, {"name": "guider", "type": "GUIDER", "link": 30, "slot_index": 1}, {"name": "sampler", "type": "SAMPLER", "link": 19, "slot_index": 2}, {"name": "sigmas", "type": "SIGMAS", "link": 20, "slot_index": 3}, {"name": "latent_image", "type": "LATENT", "link": 116, "slot_index": 4}], "outputs": [{"name": "output", "type": "LATENT", "links": [24], "slot_index": 0, "shape": 3}, {"name": "denoised_output", "type": "LATENT", "links": null, "shape": 3}], "properties": {"Node name for S&R": "SamplerCustomAdvanced"}}, {"id": 25, "type": "RandomNoise", "pos": [480, 768], "size": {"0": 315, "1": 82}, "flags": {}, "order": 1, "mode": 0, "outputs": [{"name": "NOISE", "type": "NOISE", "links": [37], "shape": 3}], "properties": {"Node name for S&R": "RandomNoise"}, "widgets_values": [219670278747233, "randomize"], "color": "#2a363b", "bgcolor": "#3f5159"}, {"id": 8, "type": "VAEDecode", "pos": [866, 367], "size": {"0": 210, "1": 46}, "flags": {}, "order": 16, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 24}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [9], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}}, {"id": 30, "type": "ModelSamplingFlux", "pos": [480, 1152], "size": {"0": 315, "1": 130}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 56, "slot_index": 0}, {"name": "width", "type": "INT", "link": 115, "slot_index": 1, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": 114, "slot_index": 2, "widget": {"name": "height"}}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [54, 55], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "ModelSamplingFlux"}, "widgets_values": [1.15, 0.5, 1024, 1024]}, {"id": 27, "type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": 112, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": 113, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [116], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 34, "type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 2, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [112, 115], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 35, "type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 3, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [113, 114], "slot_index": 0, "widget": {"name": "height"}}], "title": "height", "properties": {"Run widget replace on values": false}, "widgets_values": [1024, "fixed"], "color": "#323", "bgcolor": "#535"}, {"id": 12, "type": "UNETLoader", "pos": [48, 144], "size": {"0": 315, "1": 82}, "flags": {}, "order": 4, "mode": 0, "outputs": [{"name": "MODEL", "type": "MODEL", "links": [56], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["flux1-dev.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 9, "type": "SaveImage", "pos": [1155, 196], "size": {"0": 985.3012084960938, "1": 1060.3828125}, "flags": {}, "order": 17, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 37, "type": "Note", "pos": [480, 1344], "size": {"0": 314.99755859375, "1": 117.98363494873047}, "flags": {}, "order": 5, "mode": 0, "properties": {"text": ""}, "widgets_values": ["The reference sampling implementation auto adjusts the shift value based on the resolution, if you don't want this you can just bypass (CTRL-B) this ModelSamplingFlux node.\n"], "color": "#432", "bgcolor": "#653"}, {"id": 10, "type": "VAELoader", "pos": [48, 432], "size": {"0": 311.81634521484375, "1": 60.429901123046875}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "VAE", "type": "VAE", "links": [12], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["ae.safetensors"]}, {"id": 28, "type": "Note", "pos": [48, 576], "size": {"0": 336, "1": 288}, "flags": {}, "order": 7, "mode": 0, "properties": {"text": ""}, "widgets_values": ["If you get an error in any of the nodes above make sure the files are in the correct directories.\n\nSee the top of the examples page for the links : https://comfyanonymous.github.io/ComfyUI_examples/flux/\n\nflux1-dev.safetensors goes in: ComfyUI/models/unet/\n\nt5xxl_fp16.safetensors and clip_l.safetensors go in: ComfyUI/models/clip/\n\nae.safetensors goes in: ComfyUI/models/vae/\n\n\nTip: You can set the weight_dtype above to one of the fp8 types if you have memory issues."], "color": "#432", "bgcolor": "#653"}, {"id": 11, "type": "DualCLIPLoader", "pos": [48, 288], "size": {"0": 315, "1": 106}, "flags": {}, "order": 8, "mode": 0, "outputs": [{"name": "CLIP", "type": "CLIP", "links": [10], "slot_index": 0, "shape": 3}], "properties": {"Node name for S&R": "DualCLIPLoader"}, "widgets_values": ["t5xxl_fp16.safetensors", "clip_l.safetensors", "flux"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [384, 240], "size": {"0": 422.84503173828125, "1": 164.31304931640625}, "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 10}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [41], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["mulan standing in front of a rice paddy"], "color": "#232", "bgcolor": "#353"}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [10, 11, 0, 6, 0, "CLIP"], [12, 10, 0, 8, 1, "VAE"], [19, 16, 0, 13, 2, "SAMPLER"], [20, 17, 0, 13, 3, "SIGMAS"], [24, 13, 0, 8, 0, "LATENT"], [30, 22, 0, 13, 1, "GUIDER"], [37, 25, 0, 13, 0, "NOISE"], [41, 6, 0, 26, 0, "CONDITIONING"], [42, 26, 0, 22, 1, "CONDITIONING"], [54, 30, 0, 22, 0, "MODEL"], [55, 30, 0, 17, 0, "MODEL"], [56, 12, 0, 30, 0, "MODEL"], [112, 34, 0, 27, 0, "INT"], [113, 35, 0, 27, 1, "INT"], [114, 35, 0, 30, 2, "INT"], [115, 34, 0, 30, 1, "INT"], [116, 27, 0, 13, 4, "LATENT"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.1, "offset": [322.24494099375903, 85.92545875142977]}, "groupNodes": {}}, "version": 0.4}}]}