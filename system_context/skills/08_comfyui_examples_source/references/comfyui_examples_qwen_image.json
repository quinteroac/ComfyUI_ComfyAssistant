{"category": "qwen_image", "entries": [{"source": "image-metadata", "image": "qwen_image/qwen_image_basic_example.png", "prompt": {"3": {"inputs": {"seed": 1091359629774730, "steps": 20, "cfg": 2.5, "sampler_name": "euler", "scheduler": "simple", "denoise": 1.0, "model": ["66", 0], "positive": ["6", 0], "negative": ["7", 0], "latent_image": ["58", 0]}, "class_type": "KSampler", "_meta": {"title": "KSampler"}}, "6": {"inputs": {"text": "cute anime girl with massive fennec ears and a big fluffy fox tail with long wavy blonde hair between eyes and large blue eyes blonde colored eyelashes chubby wearing oversized clothes summer uniform long blue maxi skirt muddy clothes happy sitting on the side of the road in a run down dark gritty cyberpunk city with neon and a crumbling skyscraper in the rain at night while dipping her feet in a river of water she is holding a sign that says \"ComfyUI is the best\" written in cursive", "clip": ["38", 0]}, "class_type": "CLIPTextEncode", "_meta": {"title": "CLIP Text Encode (Positive Prompt)"}}, "7": {"inputs": {"text": " ", "clip": ["38", 0]}, "class_type": "CLIPTextEncode", "_meta": {"title": "CLIP Text Encode (Negative Prompt)"}}, "8": {"inputs": {"samples": ["3", 0], "vae": ["39", 0]}, "class_type": "VAEDecode", "_meta": {"title": "VAE Decode"}}, "37": {"inputs": {"unet_name": "qwen_image_fp8_e4m3fn.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader", "_meta": {"title": "Load Diffusion Model"}}, "38": {"inputs": {"clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors", "type": "qwen_image", "device": "default"}, "class_type": "CLIPLoader", "_meta": {"title": "Load CLIP"}}, "39": {"inputs": {"vae_name": "qwen_image_vae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}}, "58": {"inputs": {"width": 1328, "height": 1328, "batch_size": 1}, "class_type": "EmptySD3LatentImage", "_meta": {"title": "EmptySD3LatentImage"}}, "60": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage", "_meta": {"title": "Save Image"}}, "66": {"inputs": {"shift": 3.1000000000000005, "model": ["37", 0]}, "class_type": "ModelSamplingAuraFlow", "_meta": {"title": "ModelSamplingAuraFlow"}}}, "workflow": {"id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb", "revision": 0, "last_node_id": 68, "last_link_id": 128, "nodes": [{"id": 39, "type": "VAELoader", "pos": [20, 340], "size": [330, 60], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [76]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["qwen_image_vae.safetensors"], "color": "#223", "bgcolor": "#335"}, {"id": 8, "type": "VAEDecode", "pos": [1210, 190], "size": [210, 46], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 128}, {"name": "vae", "type": "VAE", "link": 76}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [110]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 60, "type": "SaveImage", "pos": [1478.3486328125, 190.30274963378906], "size": [821.0496215820312, 871.7067260742188], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 110}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 58, "type": "EmptySD3LatentImage", "pos": [410.6574401855469, 620.5468139648438], "size": [270, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [107]}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1328, 1328, 1]}, {"id": 7, "type": "CLIPTextEncode", "pos": [413, 389], "size": [425.27801513671875, 180.6060791015625], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 75}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [52]}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": [" "], "color": "#322", "bgcolor": "#533"}, {"id": 37, "type": "UNETLoader", "pos": [20, 60], "size": [346.7470703125, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [126]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["qwen_image_fp8_e4m3fn.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 38, "type": "CLIPLoader", "pos": [20, 190], "size": [380, 106], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "slot_index": 0, "links": [74, 75]}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["qwen_2.5_vl_7b_fp8_scaled.safetensors", "qwen_image", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 66, "type": "ModelSamplingAuraFlow", "pos": [418.2298278808594, 68.82577514648438], "size": [270, 58], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 126}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [125]}], "properties": {"Node name for S&R": "ModelSamplingAuraFlow"}, "widgets_values": [3.1000000000000005]}, {"id": 6, "type": "CLIPTextEncode", "pos": [415, 186], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 74}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [46]}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["cute anime girl with massive fennec ears and a big fluffy fox tail with long wavy blonde hair between eyes and large blue eyes blonde colored eyelashes chubby wearing oversized clothes summer uniform long blue maxi skirt muddy clothes happy sitting on the side of the road in a run down dark gritty cyberpunk city with neon and a crumbling skyscraper in the rain at night while dipping her feet in a river of water she is holding a sign that says \"ComfyUI is the best\" written in cursive"], "color": "#232", "bgcolor": "#353"}, {"id": 68, "type": "Note", "pos": [419.86859130859375, -75.3620834350586], "size": [261.87744140625, 102.99000549316406], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [], "properties": {}, "widgets_values": ["Increase the shift if you get too many blury/dark/bad images. Decrease if you want to try increasing detail."], "color": "#432", "bgcolor": "#653"}, {"id": 67, "type": "Note", "pos": [870.09619140625, 495.96044921875], "size": [307.4002380371094, 127.38092803955078], "flags": {}, "order": 5, "mode": 0, "inputs": [], "outputs": [], "properties": {}, "widgets_values": ["Set cfg to 1.0 for a speed boost at the cost of consistency. Samplers like res_multistep work pretty well at cfg 1.0\n\nThe official number of steps is 50 but I think that's too much. Even just 10 steps seems to work."], "color": "#432", "bgcolor": "#653"}, {"id": 3, "type": "KSampler", "pos": [863, 187], "size": [315, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 125}, {"name": "positive", "type": "CONDITIONING", "link": 46}, {"name": "negative", "type": "CONDITIONING", "link": 52}, {"name": "latent_image", "type": "LATENT", "link": 107}], "outputs": [{"name": "LATENT", "type": "LATENT", "slot_index": 0, "links": [128]}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [1091359629774730, "randomize", 20, 2.5, "euler", "simple", 1]}], "links": [[46, 6, 0, 3, 1, "CONDITIONING"], [52, 7, 0, 3, 2, "CONDITIONING"], [74, 38, 0, 6, 0, "CLIP"], [75, 38, 0, 7, 0, "CLIP"], [76, 39, 0, 8, 1, "VAE"], [107, 58, 0, 3, 3, "LATENT"], [110, 8, 0, 60, 0, "IMAGE"], [125, 66, 0, 3, 0, "MODEL"], [126, 37, 0, 66, 0, "MODEL"], [128, 3, 0, 8, 0, "LATENT"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.922959981770648, "offset": [7.690544275060104, 119.39329164298258]}, "frontendVersion": "1.23.4"}, "version": 0.4}}, {"source": "image-metadata", "image": "qwen_image/qwen_image_edit_2509_basic_example.png", "prompt": {"8": {"inputs": {"samples": ["65", 0], "vae": ["10", 0]}, "class_type": "VAEDecode", "_meta": {"title": "VAE Decode"}}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage", "_meta": {"title": "Save Image"}}, "10": {"inputs": {"vae_name": "qwen_image_vae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}}, "12": {"inputs": {"unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader", "_meta": {"title": "Load Diffusion Model"}}, "41": {"inputs": {"image": "fennec_girl_sing.png"}, "class_type": "LoadImage", "_meta": {"title": "Load Image"}, "is_changed": ["8da6d35e6206689be1ac0d44e693a7eb13babffda52318c7a99b4f03cc8aa773"]}, "61": {"inputs": {"clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors", "type": "qwen_image", "device": "default"}, "class_type": "CLIPLoader", "_meta": {"title": "Load CLIP"}}, "65": {"inputs": {"seed": 643571810992611, "steps": 20, "cfg": 4.0, "sampler_name": "euler", "scheduler": "simple", "denoise": 1.0, "model": ["67", 0], "positive": ["68", 0], "negative": ["69", 0], "latent_image": ["66", 0]}, "class_type": "KSampler", "_meta": {"title": "KSampler"}}, "66": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage", "_meta": {"title": "EmptySD3LatentImage"}}, "67": {"inputs": {"shift": 3.1, "model": ["12", 0]}, "class_type": "ModelSamplingAuraFlow", "_meta": {"title": "ModelSamplingAuraFlow"}}, "68": {"inputs": {"prompt": "the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwich beside a beautiful alpine lake", "clip": ["61", 0], "vae": ["10", 0], "image1": ["41", 0]}, "class_type": "TextEncodeQwenImageEditPlus", "_meta": {"title": "TextEncodeQwenImageEditPlus (Positive)"}}, "69": {"inputs": {"prompt": "", "clip": ["61", 0], "vae": ["10", 0], "image1": ["41", 0]}, "class_type": "TextEncodeQwenImageEditPlus", "_meta": {"title": "TextEncodeQwenImageEditPlus"}}}, "workflow": {"id": "ad18abd3-bdee-4f80-8fae-d15d4f845b9d", "revision": 0, "last_node_id": 69, "last_link_id": 185, "nodes": [{"id": 67, "type": "ModelSamplingAuraFlow", "pos": [115.86839294433594, -103.43475341796875], "size": [270, 58], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 176}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [177]}], "properties": {"Node name for S&R": "ModelSamplingAuraFlow"}, "widgets_values": [3.1]}, {"id": 8, "type": "VAEDecode", "pos": [1020, -10], "size": [210, 46], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 175}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [9]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 9, "type": "SaveImage", "pos": [1250, -10], "size": [985.3012084960938, 1060.3828125], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 61, "type": "CLIPLoader", "pos": [-300, 20], "size": [382, 106], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [178, 181]}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["qwen_2.5_vl_7b_fp8_scaled.safetensors", "qwen_image", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 66, "type": "EmptySD3LatentImage", "pos": [219.75479125976562, 566.0596923828125], "size": [270, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [174]}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 69, "type": "TextEncodeQwenImageEditPlus", "pos": [120, 300], "size": [420, 220], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 181}, {"name": "vae", "shape": 7, "type": "VAE", "link": 185}, {"name": "image1", "shape": 7, "type": "IMAGE", "link": 183}, {"name": "image2", "shape": 7, "type": "IMAGE", "link": null}, {"name": "image3", "shape": 7, "type": "IMAGE", "link": null}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [179]}], "properties": {"Node name for S&R": "TextEncodeQwenImageEditPlus"}, "widgets_values": [""], "color": "#322", "bgcolor": "#533"}, {"id": 10, "type": "VAELoader", "pos": [-230, 160], "size": [311.81634521484375, 60.429901123046875], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [12, 184, 185]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["qwen_image_vae.safetensors"], "color": "#223", "bgcolor": "#335"}, {"id": 41, "type": "LoadImage", "pos": [-260.10516357421875, 292.7162780761719], "size": [274.080078125, 314], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [182, 183]}, {"name": "MASK", "type": "MASK", "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["fennec_girl_sing.png", "image"]}, {"id": 68, "type": "TextEncodeQwenImageEditPlus", "pos": [114.59521484375, -1.1091564893722534], "size": [426.63751220703125, 265.5693054199219], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 178}, {"name": "vae", "shape": 7, "type": "VAE", "link": 184}, {"name": "image1", "shape": 7, "type": "IMAGE", "link": 182}, {"name": "image2", "shape": 7, "type": "IMAGE", "link": null}, {"name": "image3", "shape": 7, "type": "IMAGE", "link": null}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [180]}], "title": "TextEncodeQwenImageEditPlus (Positive)", "properties": {"Node name for S&R": "TextEncodeQwenImageEditPlus"}, "widgets_values": ["the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwich beside a beautiful alpine lake"], "color": "#232", "bgcolor": "#353"}, {"id": 65, "type": "KSampler", "pos": [730, -10], "size": [270, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 171}, {"name": "positive", "type": "CONDITIONING", "link": 180}, {"name": "negative", "type": "CONDITIONING", "link": 179}, {"name": "latent_image", "type": "LATENT", "link": 174}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [175]}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [643571810992611, "randomize", 20, 4, "euler", "simple", 1]}, {"id": 12, "type": "UNETLoader", "pos": [-310, -100], "size": [396.1419982910156, 82], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [176]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["qwen_image_edit_2509_fp8_e4m3fn.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 64, "type": "CFGNorm", "pos": [410, -100], "size": [270, 58], "flags": {}, "order": 8, "mode": 4, "inputs": [{"name": "model", "type": "MODEL", "link": 177}], "outputs": [{"name": "patched_model", "type": "MODEL", "links": [171]}], "properties": {"Node name for S&R": "CFGNorm"}, "widgets_values": [1]}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [12, 10, 0, 8, 1, "VAE"], [171, 64, 0, 65, 0, "MODEL"], [174, 66, 0, 65, 3, "LATENT"], [175, 65, 0, 8, 0, "LATENT"], [176, 12, 0, 67, 0, "MODEL"], [177, 67, 0, 64, 0, "MODEL"], [178, 61, 0, 68, 0, "CLIP"], [179, 69, 0, 65, 2, "CONDITIONING"], [180, 68, 0, 65, 1, "CONDITIONING"], [181, 61, 0, 69, 0, "CLIP"], [182, 41, 0, 68, 2, "IMAGE"], [183, 41, 0, 69, 2, "IMAGE"], [184, 10, 0, 68, 1, "VAE"], [185, 10, 0, 69, 1, "VAE"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.2100000000000002, "offset": [327.5978586691468, 158.00469335539492]}, "frontendVersion": "1.26.11", "groupNodes": {"EmptyLatentImage": {"nodes": [{"type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 0}, {"type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 1}, {"type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": null, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": null, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "index": 2}], "links": [[1, 0, 2, 0, 34, "INT"], [0, 0, 2, 1, 35, "INT"]], "external": [[0, 0, "INT"], [1, 0, "INT"], [2, 0, "LATENT"]], "config": {"0": {"output": {"0": {"name": "height"}}, "input": {"value": {"visible": true}}}, "1": {"output": {"0": {"name": "width"}}, "input": {"value": {"visible": true}}}, "2": {"input": {"width": {"visible": false}, "height": {"visible": false}}}}}}}, "version": 0.4}}, {"source": "image-metadata", "image": "qwen_image/qwen_image_edit_basic_example.png", "prompt": {"8": {"inputs": {"samples": ["65", 0], "vae": ["10", 0]}, "class_type": "VAEDecode", "_meta": {"title": "VAE Decode"}}, "9": {"inputs": {"filename_prefix": "ComfyUI", "images": ["8", 0]}, "class_type": "SaveImage", "_meta": {"title": "Save Image"}}, "10": {"inputs": {"vae_name": "qwen_image_vae.safetensors"}, "class_type": "VAELoader", "_meta": {"title": "Load VAE"}}, "12": {"inputs": {"unet_name": "qwen_image_edit_fp8_e4m3fn.safetensors", "weight_dtype": "default"}, "class_type": "UNETLoader", "_meta": {"title": "Load Diffusion Model"}}, "41": {"inputs": {"image": "fennec_girl_sing.png"}, "class_type": "LoadImage", "_meta": {"title": "Load Image"}, "is_changed": ["8da6d35e6206689be1ac0d44e693a7eb13babffda52318c7a99b4f03cc8aa773"]}, "60": {"inputs": {"prompt": "the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwich beside a beautiful alpine lake", "clip": ["61", 0], "vae": ["10", 0], "image": ["41", 0]}, "class_type": "TextEncodeQwenImageEdit", "_meta": {"title": "TextEncodeQwenImageEdit (Positive)"}}, "61": {"inputs": {"clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors", "type": "qwen_image", "device": "default"}, "class_type": "CLIPLoader", "_meta": {"title": "Load CLIP"}}, "63": {"inputs": {"prompt": " ", "clip": ["61", 0], "vae": ["10", 0], "image": ["41", 0]}, "class_type": "TextEncodeQwenImageEdit", "_meta": {"title": "TextEncodeQwenImageEdit (Negative)"}}, "64": {"inputs": {"strength": 1.0, "model": ["67", 0]}, "class_type": "CFGNorm", "_meta": {"title": "CFGNorm"}}, "65": {"inputs": {"seed": 643571810992611, "steps": 20, "cfg": 4.0, "sampler_name": "euler", "scheduler": "simple", "denoise": 1.0, "model": ["64", 0], "positive": ["60", 0], "negative": ["63", 0], "latent_image": ["66", 0]}, "class_type": "KSampler", "_meta": {"title": "KSampler"}}, "66": {"inputs": {"width": 1024, "height": 1024, "batch_size": 1}, "class_type": "EmptySD3LatentImage", "_meta": {"title": "EmptySD3LatentImage"}}, "67": {"inputs": {"shift": 3.1, "model": ["12", 0]}, "class_type": "ModelSamplingAuraFlow", "_meta": {"title": "ModelSamplingAuraFlow"}}}, "workflow": {"id": "ad18abd3-bdee-4f80-8fae-d15d4f845b9d", "revision": 0, "last_node_id": 67, "last_link_id": 177, "nodes": [{"id": 10, "type": "VAELoader", "pos": [-230, 160], "size": [311.81634521484375, 60.429901123046875], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [12, 164, 168]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["qwen_image_vae.safetensors"], "color": "#223", "bgcolor": "#335"}, {"id": 61, "type": "CLIPLoader", "pos": [-300, 20], "size": [382, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [166, 167]}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["qwen_2.5_vl_7b_fp8_scaled.safetensors", "qwen_image", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 67, "type": "ModelSamplingAuraFlow", "pos": [115.86839294433594, -103.43475341796875], "size": [270, 58], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 176}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [177]}], "properties": {"Node name for S&R": "ModelSamplingAuraFlow"}, "widgets_values": [3.1]}, {"id": 64, "type": "CFGNorm", "pos": [410, -100], "size": [270, 58], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 177}], "outputs": [{"name": "patched_model", "type": "MODEL", "links": [171]}], "properties": {"Node name for S&R": "CFGNorm"}, "widgets_values": [1]}, {"id": 12, "type": "UNETLoader", "pos": [-310, -100], "size": [396.1419982910156, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [176]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["qwen_image_edit_fp8_e4m3fn.safetensors", "default"], "color": "#223", "bgcolor": "#335"}, {"id": 41, "type": "LoadImage", "pos": [-200, 260], "size": [274.080078125, 314], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [162, 169]}, {"name": "MASK", "type": "MASK", "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["fennec_girl_sing.png", "image"]}, {"id": 66, "type": "EmptySD3LatentImage", "pos": [230, 480], "size": [270, 106], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [174]}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1]}, {"id": 8, "type": "VAEDecode", "pos": [1020, -10], "size": [210, 46], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 175}, {"name": "vae", "type": "VAE", "link": 12}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [9]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 9, "type": "SaveImage", "pos": [1250, -10], "size": [985.3012084960938, 1060.3828125], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 9}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI"]}, {"id": 63, "type": "TextEncodeQwenImageEdit", "pos": [110, 230], "size": [400, 200], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 167}, {"name": "vae", "shape": 7, "type": "VAE", "link": 168}, {"name": "image", "shape": 7, "type": "IMAGE", "link": 169}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [173]}], "title": "TextEncodeQwenImageEdit (Negative)", "properties": {"Node name for S&R": "TextEncodeQwenImageEdit"}, "widgets_values": [" "], "color": "#322", "bgcolor": "#533"}, {"id": 60, "type": "TextEncodeQwenImageEdit", "pos": [110, -10], "size": [400, 200], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 166}, {"name": "vae", "shape": 7, "type": "VAE", "link": 164}, {"name": "image", "shape": 7, "type": "IMAGE", "link": 162}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [172]}], "title": "TextEncodeQwenImageEdit (Positive)", "properties": {"Node name for S&R": "TextEncodeQwenImageEdit"}, "widgets_values": ["the anime girl with massive fennec ears is wearing cargo pants while sitting on a log in the woods biting into a sandwich beside a beautiful alpine lake"], "color": "#232", "bgcolor": "#353"}, {"id": 65, "type": "KSampler", "pos": [730, -10], "size": [270, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 171}, {"name": "positive", "type": "CONDITIONING", "link": 172}, {"name": "negative", "type": "CONDITIONING", "link": 173}, {"name": "latent_image", "type": "LATENT", "link": 174}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [175]}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [643571810992611, "randomize", 20, 4, "euler", "simple", 1]}], "links": [[9, 8, 0, 9, 0, "IMAGE"], [12, 10, 0, 8, 1, "VAE"], [162, 41, 0, 60, 2, "IMAGE"], [164, 10, 0, 60, 1, "VAE"], [166, 61, 0, 60, 0, "CLIP"], [167, 61, 0, 63, 0, "CLIP"], [168, 10, 0, 63, 1, "VAE"], [169, 41, 0, 63, 2, "IMAGE"], [171, 64, 0, 65, 0, "MODEL"], [172, 60, 0, 65, 1, "CONDITIONING"], [173, 63, 0, 65, 2, "CONDITIONING"], [174, 66, 0, 65, 3, "LATENT"], [175, 65, 0, 8, 0, "LATENT"], [176, 12, 0, 67, 0, "MODEL"], [177, 67, 0, 64, 0, "MODEL"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.9090909090909091, "offset": [360.01093333889764, 166.9274059213336]}, "frontendVersion": "1.25.9", "groupNodes": {"EmptyLatentImage": {"nodes": [{"type": "PrimitiveNode", "pos": [432, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 6, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "widget": {"name": "height"}, "slot_index": 0}], "title": "height", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 0}, {"type": "PrimitiveNode", "pos": [672, 480], "size": {"0": 210, "1": 82}, "flags": {}, "order": 7, "mode": 0, "outputs": [{"name": "INT", "type": "INT", "links": [], "slot_index": 0, "widget": {"name": "width"}}], "title": "width", "properties": {"Run widget replace on values": false}, "color": "#323", "bgcolor": "#535", "index": 1}, {"type": "EmptySD3LatentImage", "pos": [480, 624], "size": {"0": 315, "1": 106}, "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "width", "type": "INT", "link": null, "widget": {"name": "width"}}, {"name": "height", "type": "INT", "link": null, "widget": {"name": "height"}}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [], "shape": 3, "slot_index": 0}], "properties": {"Node name for S&R": "EmptySD3LatentImage"}, "widgets_values": [1024, 1024, 1], "index": 2}], "links": [[1, 0, 2, 0, 34, "INT"], [0, 0, 2, 1, 35, "INT"]], "external": [[0, 0, "INT"], [1, 0, "INT"], [2, 0, "LATENT"]], "config": {"0": {"output": {"0": {"name": "height"}}, "input": {"value": {"visible": true}}}, "1": {"output": {"0": {"name": "width"}}, "input": {"value": {"visible": true}}}, "2": {"input": {"width": {"visible": false}, "height": {"visible": false}}}}}}}, "version": 0.4}}]}