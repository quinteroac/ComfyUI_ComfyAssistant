{"category": "wan", "entries": [{"source": "json-file", "file": "wan/camera_image_to_video_wan_example.json", "prompt": {"id": "fa117b0f-052b-46d1-af50-d1bc60704ed5", "revision": 0, "last_node_id": 60, "last_link_id": 130, "nodes": [{"id": 38, "type": "CLIPLoader", "pos": [-540, 170], "size": [387.0450744628906, 106], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "slot_index": 0, "links": [74, 75]}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["umt5_xxl_fp8_e4m3fn_scaled.safetensors", "wan", "default"]}, {"id": 39, "type": "VAELoader", "pos": [590, 480], "size": [290.6003723144531, 58], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [76, 117]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["wan_2.1_vae.safetensors"]}, {"id": 3, "type": "KSampler", "pos": [900, 180], "size": [308.10516357421875, 262], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 111}, {"name": "positive", "type": "CONDITIONING", "link": 118}, {"name": "negative", "type": "CONDITIONING", "link": 119}, {"name": "latent_image", "type": "LATENT", "link": 120}], "outputs": [{"name": "LATENT", "type": "LATENT", "slot_index": 0, "links": [35]}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [1034274237172778, "randomize", 20, 6, "uni_pc", "simple", 1]}, {"id": 8, "type": "VAEDecode", "pos": [1230, 180], "size": [210, 46], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 35}, {"name": "vae", "type": "VAE", "link": 76}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [56, 93]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 28, "type": "SaveAnimatedWEBP", "pos": [1480, 180], "size": [620.66796875, 679.0053100585938], "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 56}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI", 16, false, 90, "default"]}, {"id": 7, "type": "CLIPTextEncode", "pos": [-140, 370], "size": [425.27801513671875, 180.6060791015625], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 75}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [116]}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70"], "color": "#322", "bgcolor": "#533"}, {"id": 6, "type": "CLIPTextEncode", "pos": [-140, 160], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 74}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [115]}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit"], "color": "#232", "bgcolor": "#353"}, {"id": 51, "type": "CLIPVisionEncode", "pos": [350, 680], "size": [255.5699462890625, 78], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "clip_vision", "type": "CLIP_VISION", "link": 94}, {"name": "image", "type": "IMAGE", "link": 109}], "outputs": [{"name": "CLIP_VISION_OUTPUT", "type": "CLIP_VISION_OUTPUT", "slot_index": 0, "links": [113]}], "properties": {"Node name for S&R": "CLIPVisionEncode"}, "widgets_values": ["none"]}, {"id": 52, "type": "LoadImage", "pos": [-10, 780], "size": [315, 314], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [109, 114]}, {"name": "MASK", "type": "MASK", "slot_index": 1, "links": null}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["flux_dev_example.png", "image"]}, {"id": 49, "type": "CLIPVisionLoader", "pos": [0, 670], "size": [315, 58], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "slot_index": 0, "links": [94]}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["clip_vision_h.safetensors"]}, {"id": 56, "type": "WanCameraImageToVideo", "pos": [590, 200], "size": [290, 230], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 115}, {"name": "negative", "type": "CONDITIONING", "link": 116}, {"name": "vae", "type": "VAE", "link": 117}, {"name": "clip_vision_output", "shape": 7, "type": "CLIP_VISION_OUTPUT", "link": 113}, {"name": "start_image", "shape": 7, "type": "IMAGE", "link": 114}, {"name": "camera_conditions", "shape": 7, "type": "WAN_CAMERA_EMBEDDING", "link": 124}, {"name": "width", "type": "INT", "widget": {"name": "width"}, "link": 125}, {"name": "height", "type": "INT", "widget": {"name": "height"}, "link": 126}, {"name": "length", "type": "INT", "widget": {"name": "length"}, "link": 127}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [118]}, {"name": "negative", "type": "CONDITIONING", "links": [119]}, {"name": "latent", "type": "LATENT", "links": [120]}], "properties": {"Node name for S&R": "WanCameraImageToVideo"}, "widgets_values": [832, 480, 81, 1]}, {"id": 54, "type": "ModelSamplingSD3", "pos": [600, 100], "size": [210, 58], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 130}], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [111]}], "properties": {"Node name for S&R": "ModelSamplingSD3"}, "widgets_values": [8.000000000000002]}, {"id": 47, "type": "SaveWEBM", "pos": [2150, 180], "size": [315, 210], "flags": {}, "order": 14, "mode": 4, "inputs": [{"name": "images", "type": "IMAGE", "link": 93}], "outputs": [], "properties": {"Node name for S&R": "SaveWEBM"}, "widgets_values": ["ComfyUI", "vp9", 24, 32]}, {"id": 57, "type": "WanCameraEmbedding", "pos": [310, 300], "size": [236.8000030517578, 310], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "camera_embedding", "type": "WAN_CAMERA_EMBEDDING", "links": [124]}, {"name": "width", "type": "INT", "links": [125]}, {"name": "height", "type": "INT", "links": [126]}, {"name": "length", "type": "INT", "links": [127]}], "properties": {"Node name for S&R": "WanCameraEmbedding"}, "widgets_values": ["Zoom Out", 512, 512, 81, 1, 0.5, 0.5, 0.5, 0.5]}, {"id": 37, "type": "UNETLoader", "pos": [-540, 50], "size": [390, 82], "flags": {}, "order": 5, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [130]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["wan2.1_fun_camera_v1.1_1.3B_bf16.safetensors", "default"]}], "links": [[35, 3, 0, 8, 0, "LATENT"], [56, 8, 0, 28, 0, "IMAGE"], [74, 38, 0, 6, 0, "CLIP"], [75, 38, 0, 7, 0, "CLIP"], [76, 39, 0, 8, 1, "VAE"], [93, 8, 0, 47, 0, "IMAGE"], [94, 49, 0, 51, 0, "CLIP_VISION"], [109, 52, 0, 51, 1, "IMAGE"], [111, 54, 0, 3, 0, "MODEL"], [113, 51, 0, 56, 3, "CLIP_VISION_OUTPUT"], [114, 52, 0, 56, 4, "IMAGE"], [115, 6, 0, 56, 0, "CONDITIONING"], [116, 7, 0, 56, 1, "CONDITIONING"], [117, 39, 0, 56, 2, "VAE"], [118, 56, 0, 3, 1, "CONDITIONING"], [119, 56, 1, 3, 2, "CONDITIONING"], [120, 56, 2, 3, 3, "LATENT"], [124, 57, 0, 56, 5, "WAN_CAMERA_EMBEDDING"], [125, 57, 1, 56, 6, "INT"], [126, 57, 2, 56, 7, "INT"], [127, 57, 3, 56, 8, "INT"], [130, 37, 0, 54, 0, "MODEL"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.6934334949441638, "offset": [570.9293716820114, 14.391611998548521]}, "frontendVersion": "1.20.7"}, "version": 0.4}, "workflow": null}, {"source": "json-file", "file": "wan/image_to_video_wan_example.json", "prompt": {"last_node_id": 54, "last_link_id": 111, "nodes": [{"id": 8, "type": "VAEDecode", "pos": [1210, 190], "size": [210, 46], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 35}, {"name": "vae", "type": "VAE", "link": 76}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [56, 93], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 39, "type": "VAELoader", "pos": [866.3932495117188, 499.18597412109375], "size": [306.36004638671875, 58], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [76, 99], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["wan_2.1_vae.safetensors"]}, {"id": 28, "type": "SaveAnimatedWEBP", "pos": [1460, 190], "size": [870.8511352539062, 643.7430419921875], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 56}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI", 16, false, 90, "default"]}, {"id": 47, "type": "SaveWEBM", "pos": [2367.213134765625, 193.6114959716797], "size": [315, 130], "flags": {}, "order": 13, "mode": 4, "inputs": [{"name": "images", "type": "IMAGE", "link": 93}], "outputs": [], "properties": {"Node name for S&R": "SaveWEBM"}, "widgets_values": ["ComfyUI", "vp9", 24, 32]}, {"id": 7, "type": "CLIPTextEncode", "pos": [413, 389], "size": [425.27801513671875, 180.6060791015625], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 75}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [98], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70"], "color": "#322", "bgcolor": "#533"}, {"id": 50, "type": "WanImageToVideo", "pos": [673.0507202148438, 627.272705078125], "size": [342.5999755859375, 210], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 97}, {"name": "negative", "type": "CONDITIONING", "link": 98}, {"name": "vae", "type": "VAE", "link": 99}, {"name": "clip_vision_output", "type": "CLIP_VISION_OUTPUT", "shape": 7, "link": 107}, {"name": "start_image", "type": "IMAGE", "shape": 7, "link": 106}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [101], "slot_index": 0}, {"name": "negative", "type": "CONDITIONING", "links": [102], "slot_index": 1}, {"name": "latent", "type": "LATENT", "links": [103], "slot_index": 2}], "properties": {"Node name for S&R": "WanImageToVideo"}, "widgets_values": [512, 512, 33, 1]}, {"id": 6, "type": "CLIPTextEncode", "pos": [415, 186], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 74}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [97], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around"], "color": "#232", "bgcolor": "#353"}, {"id": 3, "type": "KSampler", "pos": [863, 187], "size": [315, 262], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 111}, {"name": "positive", "type": "CONDITIONING", "link": 101}, {"name": "negative", "type": "CONDITIONING", "link": 102}, {"name": "latent_image", "type": "LATENT", "link": 103}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [35], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [987948718394761, "randomize", 20, 6, "uni_pc", "simple", 1]}, {"id": 49, "type": "CLIPVisionLoader", "pos": [20, 640], "size": [315, 58], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP_VISION", "type": "CLIP_VISION", "links": [94], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionLoader"}, "widgets_values": ["clip_vision_h.safetensors"]}, {"id": 51, "type": "CLIPVisionEncode", "pos": [360, 640], "size": [253.60000610351562, 78], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip_vision", "type": "CLIP_VISION", "link": 94}, {"name": "image", "type": "IMAGE", "link": 109}], "outputs": [{"name": "CLIP_VISION_OUTPUT", "type": "CLIP_VISION_OUTPUT", "links": [107], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPVisionEncode"}, "widgets_values": ["none"]}, {"id": 52, "type": "LoadImage", "pos": [20, 760], "size": [315, 314], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [106, 109], "slot_index": 0}, {"name": "MASK", "type": "MASK", "links": null, "slot_index": 1}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["flux_dev_example.png", "image"]}, {"id": 38, "type": "CLIPLoader", "pos": [20, 190], "size": [390, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [74, 75], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["umt5_xxl_fp8_e4m3fn_scaled.safetensors", "wan", "default"]}, {"id": 37, "type": "UNETLoader", "pos": [20, 70], "size": [346.7470703125, 82], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [110], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["wan2.1_i2v_480p_14B_fp16.safetensors", "default"]}, {"id": 54, "type": "ModelSamplingSD3", "pos": [510, 70], "size": [315, 58], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 110}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [111], "slot_index": 0}], "properties": {"Node name for S&R": "ModelSamplingSD3"}, "widgets_values": [8]}], "links": [[35, 3, 0, 8, 0, "LATENT"], [56, 8, 0, 28, 0, "IMAGE"], [74, 38, 0, 6, 0, "CLIP"], [75, 38, 0, 7, 0, "CLIP"], [76, 39, 0, 8, 1, "VAE"], [93, 8, 0, 47, 0, "IMAGE"], [94, 49, 0, 51, 0, "CLIP_VISION"], [97, 6, 0, 50, 0, "CONDITIONING"], [98, 7, 0, 50, 1, "CONDITIONING"], [99, 39, 0, 50, 2, "VAE"], [101, 50, 0, 3, 1, "CONDITIONING"], [102, 50, 1, 3, 2, "CONDITIONING"], [103, 50, 2, 3, 3, "LATENT"], [106, 52, 0, 50, 4, "IMAGE"], [107, 51, 0, 50, 3, "CLIP_VISION_OUTPUT"], [109, 52, 0, 51, 1, "IMAGE"], [110, 37, 0, 54, 0, "MODEL"], [111, 54, 0, 3, 0, "MODEL"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.015255979947749, "offset": [4.576817595742521, -17.69629597715313]}}, "version": 0.4}, "workflow": null}, {"source": "json-file", "file": "wan/text_to_video_wan.json", "prompt": {"last_node_id": 48, "last_link_id": 95, "nodes": [{"id": 8, "type": "VAEDecode", "pos": [1210, 190], "size": [210, 46], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 35}, {"name": "vae", "type": "VAE", "link": 76}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "links": [56, 93], "slot_index": 0}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 39, "type": "VAELoader", "pos": [866.3932495117188, 499.18597412109375], "size": [306.36004638671875, 58], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "links": [76], "slot_index": 0}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["wan_2.1_vae.safetensors"]}, {"id": 28, "type": "SaveAnimatedWEBP", "pos": [1460, 190], "size": [870.8511352539062, 643.7430419921875], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 56}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI", 16, false, 90, "default", ""]}, {"id": 7, "type": "CLIPTextEncode", "pos": [413, 389], "size": [425.27801513671875, 180.6060791015625], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 75}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [52], "slot_index": 0}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70"], "color": "#322", "bgcolor": "#533"}, {"id": 38, "type": "CLIPLoader", "pos": [12.94982624053955, 184.6981658935547], "size": [390, 82], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "links": [74, 75], "slot_index": 0}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["umt5_xxl_fp8_e4m3fn_scaled.safetensors", "wan", "default"]}, {"id": 40, "type": "EmptyHunyuanLatentVideo", "pos": [520, 620], "size": [315, 130], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [91], "slot_index": 0}], "properties": {"Node name for S&R": "EmptyHunyuanLatentVideo"}, "widgets_values": [832, 480, 33, 1]}, {"id": 47, "type": "SaveWEBM", "pos": [2367.213134765625, 193.6114959716797], "size": [315, 130], "flags": {}, "order": 10, "mode": 4, "inputs": [{"name": "images", "type": "IMAGE", "link": 93}], "outputs": [], "properties": {"Node name for S&R": "SaveWEBM"}, "widgets_values": ["ComfyUI", "vp9", 24, 32]}, {"id": 3, "type": "KSampler", "pos": [863, 187], "size": [315, 262], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 95}, {"name": "positive", "type": "CONDITIONING", "link": 46}, {"name": "negative", "type": "CONDITIONING", "link": 52}, {"name": "latent_image", "type": "LATENT", "link": 91}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [35], "slot_index": 0}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [82628696717253, "randomize", 30, 6, "uni_pc", "simple", 1]}, {"id": 48, "type": "ModelSamplingSD3", "pos": [440, 50], "size": [210, 58], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 94}], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [95], "slot_index": 0}], "properties": {"Node name for S&R": "ModelSamplingSD3"}, "widgets_values": [8]}, {"id": 37, "type": "UNETLoader", "pos": [20, 40], "size": [346.7470703125, 82], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "links": [94], "slot_index": 0}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["wan2.1_t2v_1.3B_fp16.safetensors", "default"]}, {"id": 6, "type": "CLIPTextEncode", "pos": [415, 186], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 4, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 74}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "links": [46], "slot_index": 0}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a fox moving quickly in a beautiful winter scenery nature trees mountains daytime tracking camera"], "color": "#232", "bgcolor": "#353"}], "links": [[35, 3, 0, 8, 0, "LATENT"], [46, 6, 0, 3, 1, "CONDITIONING"], [52, 7, 0, 3, 2, "CONDITIONING"], [56, 8, 0, 28, 0, "IMAGE"], [74, 38, 0, 6, 0, "CLIP"], [75, 38, 0, 7, 0, "CLIP"], [76, 39, 0, 8, 1, "VAE"], [91, 40, 0, 3, 3, "LATENT"], [93, 8, 0, 47, 0, "IMAGE"], [94, 37, 0, 48, 0, "MODEL"], [95, 48, 0, 3, 0, "MODEL"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 1.1167815779425205, "offset": [-5.675057867608515, 8.013751263058214]}}, "version": 0.4}, "workflow": null}, {"source": "json-file", "file": "wan/vace_reference_to_video.json", "prompt": {"id": "0898f6a6-2814-4ccd-968a-a2405ee177e7", "revision": 0, "last_node_id": 58, "last_link_id": 124, "nodes": [{"id": 39, "type": "VAELoader", "pos": [866.3932495117188, 499.18597412109375], "size": [306.36004638671875, 58], "flags": {}, "order": 0, "mode": 0, "inputs": [], "outputs": [{"name": "VAE", "type": "VAE", "slot_index": 0, "links": [76, 114]}], "properties": {"Node name for S&R": "VAELoader"}, "widgets_values": ["wan_2.1_vae.safetensors"]}, {"id": 38, "type": "CLIPLoader", "pos": [20, 190], "size": [390, 106], "flags": {}, "order": 1, "mode": 0, "inputs": [], "outputs": [{"name": "CLIP", "type": "CLIP", "slot_index": 0, "links": [74, 75]}], "properties": {"Node name for S&R": "CLIPLoader"}, "widgets_values": ["umt5_xxl_fp8_e4m3fn_scaled.safetensors", "wan", "default"]}, {"id": 54, "type": "ModelSamplingSD3", "pos": [510, 70], "size": [315, 58], "flags": {}, "order": 7, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 110}], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [111]}], "properties": {"Node name for S&R": "ModelSamplingSD3"}, "widgets_values": [8]}, {"id": 7, "type": "CLIPTextEncode", "pos": [413, 389], "size": [425.27801513671875, 180.6060791015625], "flags": {}, "order": 6, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 75}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [113]}], "title": "CLIP Text Encode (Negative Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["\u8272\u8c03\u8273\u4e3d\uff0c\u8fc7\u66dd\uff0c\u9759\u6001\uff0c\u7ec6\u8282\u6a21\u7cca\u4e0d\u6e05\uff0c\u5b57\u5e55\uff0c\u98ce\u683c\uff0c\u4f5c\u54c1\uff0c\u753b\u4f5c\uff0c\u753b\u9762\uff0c\u9759\u6b62\uff0c\u6574\u4f53\u53d1\u7070\uff0c\u6700\u5dee\u8d28\u91cf\uff0c\u4f4e\u8d28\u91cf\uff0cJPEG\u538b\u7f29\u6b8b\u7559\uff0c\u4e11\u964b\u7684\uff0c\u6b8b\u7f3a\u7684\uff0c\u591a\u4f59\u7684\u624b\u6307\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u624b\u90e8\uff0c\u753b\u5f97\u4e0d\u597d\u7684\u8138\u90e8\uff0c\u7578\u5f62\u7684\uff0c\u6bc1\u5bb9\u7684\uff0c\u5f62\u6001\u7578\u5f62\u7684\u80a2\u4f53\uff0c\u624b\u6307\u878d\u5408\uff0c\u9759\u6b62\u4e0d\u52a8\u7684\u753b\u9762\uff0c\u6742\u4e71\u7684\u80cc\u666f\uff0c\u4e09\u6761\u817f\uff0c\u80cc\u666f\u4eba\u5f88\u591a\uff0c\u5012\u7740\u8d70"], "color": "#322", "bgcolor": "#533"}, {"id": 8, "type": "VAEDecode", "pos": [1210, 190], "size": [210, 46], "flags": {}, "order": 11, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 120}, {"name": "vae", "type": "VAE", "link": 76}], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [56, 93]}], "properties": {"Node name for S&R": "VAEDecode"}, "widgets_values": []}, {"id": 56, "type": "TrimVideoLatent", "pos": [1265.2001953125, 613.80859375], "size": [270, 58], "flags": {}, "order": 10, "mode": 0, "inputs": [{"name": "samples", "type": "LATENT", "link": 119}, {"name": "trim_amount", "type": "INT", "widget": {"name": "trim_amount"}, "link": 121}], "outputs": [{"name": "LATENT", "type": "LATENT", "links": [120]}], "properties": {"Node name for S&R": "TrimVideoLatent"}, "widgets_values": [0]}, {"id": 37, "type": "UNETLoader", "pos": [20, 70], "size": [346.7470703125, 82], "flags": {}, "order": 2, "mode": 0, "inputs": [], "outputs": [{"name": "MODEL", "type": "MODEL", "slot_index": 0, "links": [110]}], "properties": {"Node name for S&R": "UNETLoader"}, "widgets_values": ["wan2.1_vace_14B_fp16.safetensors", "default"]}, {"id": 55, "type": "WanVaceToVideo", "pos": [698.0429077148438, 632.2788696289062], "size": [270, 254], "flags": {}, "order": 8, "mode": 0, "inputs": [{"name": "positive", "type": "CONDITIONING", "link": 112}, {"name": "negative", "type": "CONDITIONING", "link": 113}, {"name": "vae", "type": "VAE", "link": 114}, {"name": "control_video", "shape": 7, "type": "IMAGE", "link": null}, {"name": "control_masks", "shape": 7, "type": "MASK", "link": null}, {"name": "reference_image", "shape": 7, "type": "IMAGE", "link": 118}], "outputs": [{"name": "positive", "type": "CONDITIONING", "links": [115]}, {"name": "negative", "type": "CONDITIONING", "links": [116]}, {"name": "latent", "type": "LATENT", "links": [117]}, {"name": "trim_latent", "type": "INT", "links": [121]}], "properties": {"Node name for S&R": "WanVaceToVideo"}, "widgets_values": [768, 768, 81, 1, 1]}, {"id": 28, "type": "SaveAnimatedWEBP", "pos": [1600, 190], "size": [364.4535217285156, 510.4535217285156], "flags": {}, "order": 12, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 56}], "outputs": [], "properties": {}, "widgets_values": ["ComfyUI", 16, false, 90, "default"]}, {"id": 47, "type": "SaveWEBM", "pos": [2060, 190], "size": [429.0989685058594, 523.8981323242188], "flags": {}, "order": 13, "mode": 0, "inputs": [{"name": "images", "type": "IMAGE", "link": 93}], "outputs": [], "properties": {"Node name for S&R": "SaveWEBM"}, "widgets_values": ["ComfyUI", "vp9", 16.000000000000004, 0]}, {"id": 58, "type": "Note", "pos": [2509.27587890625, 189.5493621826172], "size": [263.95501708984375, 155.10342407226562], "flags": {}, "order": 3, "mode": 0, "inputs": [], "outputs": [], "properties": {}, "widgets_values": ["crf 0 means a lossless webm, if you want a lossy once with smaller filesize increase the crf."], "color": "#432", "bgcolor": "#653"}, {"id": 52, "type": "LoadImage", "pos": [221.9611358642578, 734.3540649414062], "size": [315, 314], "flags": {}, "order": 4, "mode": 0, "inputs": [], "outputs": [{"name": "IMAGE", "type": "IMAGE", "slot_index": 0, "links": [118]}, {"name": "MASK", "type": "MASK", "slot_index": 1, "links": []}], "properties": {"Node name for S&R": "LoadImage"}, "widgets_values": ["fennec_girl_sing.png", "image"]}, {"id": 3, "type": "KSampler", "pos": [863, 187], "size": [315, 262], "flags": {}, "order": 9, "mode": 0, "inputs": [{"name": "model", "type": "MODEL", "link": 111}, {"name": "positive", "type": "CONDITIONING", "link": 115}, {"name": "negative", "type": "CONDITIONING", "link": 116}, {"name": "latent_image", "type": "LATENT", "link": 117}], "outputs": [{"name": "LATENT", "type": "LATENT", "slot_index": 0, "links": [119]}], "properties": {"Node name for S&R": "KSampler"}, "widgets_values": [399224011392770, "randomize", 20, 6, "uni_pc", "simple", 1]}, {"id": 6, "type": "CLIPTextEncode", "pos": [415, 186], "size": [422.84503173828125, 164.31304931640625], "flags": {}, "order": 5, "mode": 0, "inputs": [{"name": "clip", "type": "CLIP", "link": 74}], "outputs": [{"name": "CONDITIONING", "type": "CONDITIONING", "slot_index": 0, "links": [112]}], "title": "CLIP Text Encode (Positive Prompt)", "properties": {"Node name for S&R": "CLIPTextEncode"}, "widgets_values": ["a cute anime girl with massive fennec ears and a big fluffy tail turning around and dancing and singing on stage like an idol"], "color": "#232", "bgcolor": "#353"}], "links": [[56, 8, 0, 28, 0, "IMAGE"], [74, 38, 0, 6, 0, "CLIP"], [75, 38, 0, 7, 0, "CLIP"], [76, 39, 0, 8, 1, "VAE"], [93, 8, 0, 47, 0, "IMAGE"], [110, 37, 0, 54, 0, "MODEL"], [111, 54, 0, 3, 0, "MODEL"], [112, 6, 0, 55, 0, "CONDITIONING"], [113, 7, 0, 55, 1, "CONDITIONING"], [114, 39, 0, 55, 2, "VAE"], [115, 55, 0, 3, 1, "CONDITIONING"], [116, 55, 1, 3, 2, "CONDITIONING"], [117, 55, 2, 3, 3, "LATENT"], [118, 52, 0, 55, 5, "IMAGE"], [119, 3, 0, 56, 0, "LATENT"], [120, 56, 0, 8, 0, "LATENT"], [121, 55, 3, 56, 1, "INT"]], "groups": [], "config": {}, "extra": {"ds": {"scale": 0.9358232486220777, "offset": [-2.3933794268561357, -27.125629672645054]}, "frontendVersion": "1.19.9"}, "version": 0.4}, "workflow": null}]}