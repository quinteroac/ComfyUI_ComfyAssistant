# API key for any OpenAI-compatible provider
OPENAI_API_KEY=sk_your_api_key_here

# Base URL of the API (OpenAI-compatible). Use this to switch providers.
# Default: OpenAI API. Examples: Together, Ollama, local server.
OPENAI_API_BASE_URL=https://api.openai.com/v1

# Optional: model name (provider-specific)
# OPENAI_MODEL=gpt-4o-mini

# Optional: delay in seconds before each LLM request (default: 1.0).
# Helps avoid 429 rate limits when the agent makes several tool calls in a row.
# LLM_REQUEST_DELAY_SECONDS=1.0

# Optional: max characters from system_context injected in each request (default: 12000).
# Lower this to reduce prompt size and latency.
# LLM_SYSTEM_CONTEXT_MAX_CHARS=12000

# Optional: max characters for formatted user context block (default: 2500).
# Includes rules, SOUL/goals, and user skills summaries.
# LLM_USER_CONTEXT_MAX_CHARS=2500

# Optional: max non-system messages sent to the LLM per request (default: 24).
# Older messages are dropped from the prompt window.
# LLM_HISTORY_MAX_MESSAGES=24

# Optional: log level for the backend ("DEBUG", "INFO", "WARNING", "ERROR").
# Default: INFO
# COMFY_ASSISTANT_LOG_LEVEL=INFO

# Optional: SearXNG instance URL for web search (fallback: DuckDuckGo)
# SEARXNG_URL=http://localhost:8080

# Note: Free tiers often have rate limits (429). If you see "Rate limit exceeded",
# wait about a minute before sending again, or increase LLM_REQUEST_DELAY_SECONDS.
