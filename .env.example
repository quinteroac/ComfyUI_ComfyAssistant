# API key for the LLM provider (Groq, OpenAI, Together, local, etc.)
GROQ_API_KEY=gsk_your_api_key_here

# Base URL of the API (OpenAI-compatible). Use this to switch providers.
# Default: Groq. Examples: OpenAI, Together, Ollama, local server.
OPENAI_API_BASE_URL=https://api.groq.com/openai/v1

# Optional: model name (default: llama3-70b-8192 for Groq)
# GROQ_MODEL=llama3-70b-8192

# Optional: delay in seconds before each LLM request (default: 1.0).
# Helps avoid 429 rate limits when the agent makes several tool calls in a row.
# LLM_REQUEST_DELAY_SECONDS=1.0

# Note: Free tiers often have rate limits (429). If you see "Rate limit exceeded",
# wait about a minute before sending again, or increase LLM_REQUEST_DELAY_SECONDS.
